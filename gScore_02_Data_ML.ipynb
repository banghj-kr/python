{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banghj-kr/python/blob/gScore/gScore_02_Data_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UH07tTurigoe",
      "metadata": {
        "id": "UH07tTurigoe"
      },
      "source": [
        "# 01. 분석을 위한 기초 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7edsY_TuL5hE",
      "metadata": {
        "id": "7edsY_TuL5hE"
      },
      "source": [
        "## 01-1. 라이브러리 로딩 및 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5yViKD5xAoOg",
      "metadata": {
        "id": "5yViKD5xAoOg"
      },
      "outputs": [],
      "source": [
        "# 01-1. 필요한 라이브러리 로딩 및 함수 정의 (240808)\n",
        "print(\"01-1. 필요한 라이브러리 로딩 및 함수 정의\")\n",
        "\n",
        "# 필요한 라이브러리 로딩\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from IPython import get_ipython\n",
        "\n",
        "def check_environment():\n",
        "    try:\n",
        "        if 'google.colab' in env:  # Colab 환경\n",
        "            from google.colab import data_table, drive\n",
        "\n",
        "            # 구글 드라이브 마운트 - Colab 환경 only\n",
        "            drive.mount('/content/drive')\n",
        "\n",
        "            # 데이터프레임을 구글 코랩의 데이터 테이블로 출력 활성화 - Colab 환경 only\n",
        "            data_table.enable_dataframe_formatter()\n",
        "\n",
        "            # 기본 경로 설정\n",
        "            base_path = '/content/drive/MyDrive/Colab Notebooks/gScore/'\n",
        "            return base_path\n",
        "\n",
        "        elif 'ZMQInteractiveShell' in env:  # Jupyter 환경\n",
        "            # 기본 경로 설정\n",
        "            base_path = ''\n",
        "            return base_path\n",
        "        else:\n",
        "            return None\n",
        "    except ImportError:\n",
        "        return None\n",
        "\n",
        "# 서울 시간대 설정\n",
        "tz = pytz.timezone('Asia/Seoul')\n",
        "\n",
        "# 환경에 맞는 기본 경로 설정\n",
        "env = str(get_ipython())  # 실행 환경 확인\n",
        "base_path = check_environment()\n",
        "print(f\"  - 기본 경로를 '{base_path}'로 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# pandas display 옵션 설정\n",
        "pd.set_option('display.max_columns', 12)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "# 필요한 함수 정의\n",
        "\n",
        "# 데이터프레임의 정보 출력 함수 정의\n",
        "def display_info_in_sections(df, step=50):\n",
        "    for i in range(0, len(df.columns), step):\n",
        "        print(df.iloc[:, i:i+step].info())\n",
        "\n",
        "print(f\"  - 라이브러리 로딩 및 함수 정의를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ok9RNCza1mDq",
      "metadata": {
        "id": "Ok9RNCza1mDq"
      },
      "source": [
        "## 01-2. 데이터 로딩 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vfoiRWfgrnXL",
      "metadata": {
        "id": "vfoiRWfgrnXL"
      },
      "outputs": [],
      "source": [
        "# 01-2. 데이터 로딩 (240628)\n",
        "print(\"01-2. 데이터 로딩\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "sub_directory_name = 'Data'\n",
        "input_file_name = 'gScore_Data_Expanded.parquet'\n",
        "input_file_path = os.path.join(base_path, sub_directory_name, input_file_name)\n",
        "\n",
        "# Parquet 파일 읽기\n",
        "raw_df = pd.read_parquet(input_file_path, engine='pyarrow')\n",
        "print(f\"  - '{input_file_path}' 파일을 읽었습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Raw-Data DataFrame (raw_df):\")\n",
        "display(raw_df.head())\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"\\n  * Raw-Data DataFrame Information (raw_df):\")\n",
        "display_info_in_sections(raw_df)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MEAQEjdYKgDD",
      "metadata": {
        "id": "MEAQEjdYKgDD"
      },
      "outputs": [],
      "source": [
        "# 01-3. 필요 없는 변수 제거 (240622)\n",
        "print(\"01-3. 필요 없는 변수 제거\")\n",
        "\n",
        "# 제거할 변수 목록 설정\n",
        "remove_columns = [col for col in raw_df.columns if col.startswith(('sap_', 'st_', 'gir_', 'scrbl_', 'companion_', 'year_no', 'address')) or col.endswith('_total')]\n",
        "\n",
        "# 변수 제거\n",
        "analysis_df = raw_df.drop(columns=remove_columns)\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"  * Raw-Data DataFrame (analysis_df):\")\n",
        "display(analysis_df.head())\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"\\n  * Raw-Data DataFrame Information (analysis_df):\")\n",
        "display_info_in_sections(analysis_df)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ATB5hs86KyaT",
      "metadata": {
        "id": "ATB5hs86KyaT"
      },
      "outputs": [],
      "source": [
        "# 01-4. 주요 변수 결측치 정리 (240630)\n",
        "print(\"01-4. 주요 변수 결측치 정리\")\n",
        "\n",
        "# is_true 열을 True로 초기화\n",
        "analysis_df['is_true'] = True\n",
        "\n",
        "# 첫 번째 홀 스트로크 기록이 -1인 경우를 확인하여 'is_true'를 False로 변경\n",
        "def check_stroke_f9(row):\n",
        "    return row['stroke_f9_1'] != -1\n",
        "\n",
        "# is_true 열을 조건에 따라 변경\n",
        "analysis_df['is_true'] = analysis_df.apply(check_stroke_f9, axis=1)\n",
        "\n",
        "# is_true가 False인 행의 특정 열 값을 NaN으로 변경\n",
        "def clear_false_rows(row):\n",
        "    if not row['is_true']:\n",
        "        for i in range(1, 10):\n",
        "            row[f'stroke_f9_{i}'] = np.nan\n",
        "            row[f'putt_f9_{i}'] = np.nan\n",
        "            row[f'penalty_f9_{i}'] = np.nan\n",
        "            row[f'fw_hit_f9_{i}'] = np.nan\n",
        "            row[f'stroke_b9_{i}'] = np.nan\n",
        "            row[f'putt_b9_{i}'] = np.nan\n",
        "            row[f'penalty_b9_{i}'] = np.nan\n",
        "            row[f'fw_hit_b9_{i}'] = np.nan\n",
        "    return row\n",
        "\n",
        "# 적용\n",
        "analysis_df = analysis_df.apply(clear_false_rows, axis=1)\n",
        "\n",
        "# 결과 확인\n",
        "print(\"  - is_true가 False인 행의 수정 결과:\")\n",
        "print(analysis_df.loc[~analysis_df['is_true'], [f'stroke_f9_{i}' for i in range(1, 10)] +\n",
        "                      [f'putt_f9_{i}' for i in range(1, 10)] +\n",
        "                      [f'penalty_f9_{i}' for i in range(1, 10)] +\n",
        "                      [f'fw_hit_f9_{i}' for i in range(1, 10)] + ['is_true']].head(10))\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Raw-Data DataFrame (analysis_df):\")\n",
        "display(analysis_df.head(5))\n",
        "display(analysis_df.tail(5))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"\\n  * Raw-Data DataFrame Information (analysis_df):\")\n",
        "display_info_in_sections(analysis_df)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RnIJ25qXKyKY",
      "metadata": {
        "id": "RnIJ25qXKyKY"
      },
      "outputs": [],
      "source": [
        "# 01-5. 라운딩 데이터를 홀 단위로 정리 (240622)\n",
        "print(\"01-5. 라운딩 데이터를 홀 단위로 정리\")\n",
        "\n",
        "# 새로운 데이터프레임을 담을 리스트\n",
        "expanded_data = []\n",
        "\n",
        "# 각 라운딩 데이터를 홀 단위로 분리\n",
        "for idx, row in analysis_df.iterrows():\n",
        "    for i in range(9):\n",
        "        # 전반 9홀 데이터 추가\n",
        "        expanded_data.append({\n",
        "            'date_time': row['date_time'],\n",
        "            'no': row['no'],\n",
        "            'golf_course': row['golf_course'],\n",
        "            'course': row['course_f9'],\n",
        "            'course_type': 'f9',\n",
        "            'hole_no': i + 1,\n",
        "            'score': row[f'score_f9_{i+1}'],\n",
        "            'stroke': row[f'stroke_f9_{i+1}'] if pd.notna(row[f'stroke_f9_{i+1}']) else None,\n",
        "            'putt': row[f'putt_f9_{i+1}'] if pd.notna(row[f'putt_f9_{i+1}']) else None,\n",
        "            'penalty': row[f'penalty_f9_{i+1}'] if pd.notna(row[f'penalty_f9_{i+1}']) else None,\n",
        "            'par': row[f'par_f9_{i+1}'] if pd.notna(row[f'par_f9_{i+1}']) else None,\n",
        "            'fw_hit': row[f'fw_hit_f9_{i+1}'] if pd.notna(row[f'fw_hit_f9_{i+1}']) else None,\n",
        "            'is_true': row['is_true']\n",
        "        })\n",
        "\n",
        "        # 후반 9홀 데이터 추가\n",
        "        expanded_data.append({\n",
        "            'date_time': row['date_time'],\n",
        "            'no': row['no'],\n",
        "            'golf_course': row['golf_course'],\n",
        "            'course': row['course_b9'],\n",
        "            'course_type': 'b9',\n",
        "            'hole_no': i + 1,\n",
        "            'score': row[f'score_b9_{i+1}'],\n",
        "            'stroke': row[f'stroke_b9_{i+1}'] if pd.notna(row[f'stroke_b9_{i+1}']) else None,\n",
        "            'putt': row[f'putt_b9_{i+1}'] if pd.notna(row[f'putt_b9_{i+1}']) else None,\n",
        "            'penalty': row[f'penalty_b9_{i+1}'] if pd.notna(row[f'penalty_b9_{i+1}']) else None,\n",
        "            'par': row[f'par_b9_{i+1}'] if pd.notna(row[f'par_b9_{i+1}']) else None,\n",
        "            'fw_hit': row[f'fw_hit_b9_{i+1}'] if pd.notna(row[f'fw_hit_b9_{i+1}']) else None,\n",
        "            'is_true': row['is_true']\n",
        "        })\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "expanded_df = pd.DataFrame(expanded_data)\n",
        "\n",
        "# 정렬\n",
        "expanded_df.sort_values(by=['date_time', 'course_type', 'hole_no'], ascending=[True, False, True], inplace=True)\n",
        "\n",
        "# 인덱스 재설정\n",
        "expanded_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Expanded Data DataFrame (expanded_df):\")\n",
        "display(expanded_df.head(5))\n",
        "display(expanded_df.tail(5))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"\\n  * Expanded Data DataFrame Information (expanded_df):\")\n",
        "display_info_in_sections(expanded_df)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TFpqRc1-snmk",
      "metadata": {
        "id": "TFpqRc1-snmk"
      },
      "outputs": [],
      "source": [
        "# 01-6. 머신러닝을 위한 데이터 처리 (240622)\n",
        "print(\"01-6. 머신러닝을 위한 데이터 처리\")\n",
        "\n",
        "# date_time 변수를 날짜와 시간 관련 변수로 변환\n",
        "expanded_df['date_time'] = pd.to_datetime(expanded_df['date_time'])\n",
        "expanded_df['month'] = expanded_df['date_time'].dt.month\n",
        "expanded_df['hour'] = expanded_df['date_time'].dt.hour\n",
        "expanded_df['season'] = expanded_df['date_time'].dt.month % 12 // 3 + 1  # 봄=1, 여름=2, 가을=3, 겨울=4\n",
        "\n",
        "# 분석에 사용할 변수 목록 설정\n",
        "features = ['no', 'hole_no', 'par', 'month', 'hour', 'season']\n",
        "\n",
        "# course_type을 원핫 인코딩하고 하나의 변수를 제거\n",
        "expanded_df = pd.get_dummies(expanded_df, columns=['course_type'])\n",
        "expanded_df.drop(columns=['course_type_f9'], inplace=True)  # course_type_f9 변수 제거\n",
        "\n",
        "# 머신러닝을 위한 데이터프레임 분리\n",
        "train_df = expanded_df[expanded_df['is_true']].copy()\n",
        "predict_df = expanded_df[~expanded_df['is_true']].copy()\n",
        "\n",
        "# 새로운 파생 변수 생성\n",
        "train_df['score_minus_stroke'] = train_df['score'] - train_df['stroke']\n",
        "train_df['score_minus_stroke_minus_penalty'] = train_df['score_minus_stroke'] - train_df['penalty']\n",
        "predict_df['score_minus_stroke'] = predict_df['score'] - predict_df['stroke']\n",
        "predict_df['score_minus_stroke_minus_penalty'] = predict_df['score_minus_stroke'] - predict_df['penalty']\n",
        "\n",
        "# stroke 예측을 위한 데이터\n",
        "X_train_stroke = train_df[features + ['course_type_b9', 'score']]\n",
        "y_train_stroke = train_df['stroke']\n",
        "\n",
        "# penalty 예측을 위한 데이터 (score_minus_stroke 추가)\n",
        "X_train_penalty = train_df[features + ['course_type_b9', 'score', 'stroke', 'score_minus_stroke']]\n",
        "y_train_penalty = train_df['penalty']\n",
        "\n",
        "# putt 예측을 위한 데이터 (score_minus_stroke_minus_penalty 추가)\n",
        "X_train_putt = train_df[features + ['course_type_b9', 'score', 'stroke', 'penalty', 'score_minus_stroke_minus_penalty']]\n",
        "y_train_putt = train_df['putt']\n",
        "\n",
        "# fw_hit 예측을 위한 데이터 (score_minus_stroke_minus_penalty 추가)\n",
        "X_train_fw_hit = train_df[train_df['par'] != 3][features + ['course_type_b9', 'stroke', 'penalty', 'putt']]\n",
        "y_train_fw_hit = train_df.loc[train_df['par'] != 3, 'fw_hit']\n",
        "\n",
        "# 예측을 위한 데이터프레임 준비\n",
        "X_predict_stroke = predict_df[features + ['course_type_b9', 'score']]\n",
        "X_predict_penalty = predict_df[features + ['course_type_b9', 'score', 'stroke', 'score_minus_stroke']]\n",
        "X_predict_putt = predict_df[features + ['course_type_b9', 'score', 'stroke', 'penalty', 'score_minus_stroke_minus_penalty']]\n",
        "X_predict_fw_hit = predict_df[predict_df['par'] != 3][features + ['course_type_b9', 'stroke', 'penalty', 'putt']]\n",
        "\n",
        "print(f\"  - 데이터 처리를 완료하였습니다. 학습 및 예측을 위한 데이터가 준비되었습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Training DataFrame (train_df):\")\n",
        "display(train_df.head())\n",
        "\n",
        "print(\"\\n  * Prediction DataFrame (predict_df):\")\n",
        "display(predict_df.head())\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"\\n  * Training DataFrame Information (train_df):\")\n",
        "display_info_in_sections(train_df)\n",
        "\n",
        "print(\"\\n  * Prediction DataFrame Information (predict_df):\")\n",
        "display_info_in_sections(predict_df)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ojIv-O-OiY3G",
      "metadata": {
        "id": "ojIv-O-OiY3G"
      },
      "source": [
        "# 02. 머신러닝 모델을 이용한 예측 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L1aZsFZPqOaR",
      "metadata": {
        "id": "L1aZsFZPqOaR"
      },
      "source": [
        "## 02-1. 라이브러리 로딩 및 함수 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 02-1-1. 머신러닝에 필요한 라이브러리 로딩 및 기본 설정"
      ],
      "metadata": {
        "id": "0y_yCIveE-Kd"
      },
      "id": "0y_yCIveE-Kd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U6v7TN5xDc58",
      "metadata": {
        "id": "U6v7TN5xDc58"
      },
      "outputs": [],
      "source": [
        "# 02-1-1. 머신러닝에 필요한 라이브러리 로딩 및 기본 설정 (240808)\n",
        "print(\"02-1-1. 머신러닝에 필요한 라이브러리 로딩 및 기본 설정\")\n",
        "#!pip install xgboost\n",
        "#!pip install lightgbm\n",
        "#!pip install catboost\n",
        "#!pip install shap\n",
        "# 필요한 라이브러리 로딩\n",
        "# 머신러닝 알고리즘\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor, CatBoostClassifier\n",
        "# 모델 저장 및 시각화\n",
        "import joblib\n",
        "import shap\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# 데이터 처리 및 모델 평가\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, ParameterGrid\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "# 모델 저장 기본 위치 설정\n",
        "model_sub_directory_name = 'Model'\n",
        "model_file_path = os.path.join(base_path, model_sub_directory_name)\n",
        "print(f\"  - 모델 저장 기본 위치를 '{model_file_path}'로 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 모델 저장 함수 정의\n",
        "def save_model(model, model_name, target, features):\n",
        "    model_filename = f'{model_file_path}/{model_name}_{target}.pkl'\n",
        "    joblib.dump(model, model_filename)\n",
        "    print(f\"  - 모델을 '{model_filename}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "    # 사용된 피처 이름 저장\n",
        "    features_filename = f'{model_file_path}/{model_name}_{target}_features.pkl'\n",
        "    joblib.dump(features, features_filename)\n",
        "    print(f\"  - 모델에 사용된 피처 이름을 '{features_filename}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 모델 로드 함수 정의\n",
        "def load_model(model_name, target):\n",
        "    model_filename = f'{model_file_path}/{model_name}_{target}.pkl'\n",
        "    model = joblib.load(model_filename)\n",
        "    print(f\"  - 모델({model_filename})을 읽어왔습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "    # 사용된 피처 이름 로드\n",
        "    features_filename = f'{model_file_path}/{model_name}_{target}_features.pkl'\n",
        "    features = joblib.load(features_filename)\n",
        "    print(f\"  - 모델에 사용된 피처 이름({features_filename})을 읽어왔습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "    return model, features\n",
        "\n",
        "print(f\"  - 라이브러리 로딩과 기본 설정을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# ================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t3F82l62D43S",
      "metadata": {
        "id": "t3F82l62D43S"
      },
      "source": [
        "### 02-1-2. 모델 생성 및 학습, 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "BMD6YkS4ZDH_",
      "metadata": {
        "id": "BMD6YkS4ZDH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a72b3f7-4540-4d21-d49f-35f15d2e131b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02-1-2. 모델 생성 및 학습, 평가 함수 정의\n",
            "  - 모델 생성 및 학습, 평가 함수 정의를 완료하였습니다. (2024-08-10 18:15:19)\n"
          ]
        }
      ],
      "source": [
        "# 02-1-2. 모델 생성 및 학습, 평가 함수 정의 (240703)\n",
        "print(\"02-1-2. 모델 생성 및 학습, 평가 함수 정의\")\n",
        "\n",
        "# K-Fold 교차 검증을 통한 모델 학습 및 평가 함수 정의\n",
        "def evaluate_model_with_kfold(X, y, param_grid, target_name, model_type, is_classifier=False):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)  # K-Fold 교차 검증 설정\n",
        "    best_params = None\n",
        "    best_score = float('-inf') if is_classifier else float('inf')\n",
        "    score_list = []\n",
        "    metric_names = []\n",
        "\n",
        "    param_combination_count = len(list(ParameterGrid(param_grid)))\n",
        "    current_combination = 1\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"    - {target_name} 모델 교차 검증 [{current_combination}/{param_combination_count}]\")\n",
        "        fold_scores = []\n",
        "\n",
        "        for train_index, val_index in kf.split(X):\n",
        "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "            model, *metrics = build_and_train_model(X_train, y_train, X_val, y_val, params, model_type=model_type, is_classifier=is_classifier)\n",
        "\n",
        "            fold_scores.append(metrics)\n",
        "\n",
        "        mean_scores = np.mean(fold_scores, axis=0)\n",
        "\n",
        "        # 분류 모델\n",
        "        if is_classifier:\n",
        "            accuracy = mean_scores[0]\n",
        "            if accuracy > best_score:\n",
        "                best_score = accuracy\n",
        "                best_params = params\n",
        "        # 회귀 모델\n",
        "        else:\n",
        "            mse = mean_scores[0]\n",
        "            if mse < best_score:\n",
        "                best_score = mse\n",
        "                best_params = params\n",
        "\n",
        "        score_list.append(mean_scores)\n",
        "        metric_names = ['accuracy', 'precision', 'recall', 'f1'] if is_classifier else ['mse', 'rmse', 'mae', 'r2']\n",
        "\n",
        "        current_combination += 1\n",
        "\n",
        "    print(f\"  - {target_name} 모델 교차 검증을 완료하였습니다. [최적 파라미터: {best_params}]\")\n",
        "\n",
        "    # 최적 파라미터로 모델 학습\n",
        "    best_model, *best_metrics = build_and_train_model(X, y, X, y, best_params, model_type=model_type, is_classifier=is_classifier)\n",
        "\n",
        "    return best_model, best_params, *best_metrics, metric_names\n",
        "\n",
        "# 모델 생성 및 학습 함수 정의\n",
        "def build_and_train_model(X_train, y_train, X_val, y_val, params, model_type='DecisionTree', is_classifier=False):\n",
        "    if model_type == 'DecisionTree':\n",
        "        model = DecisionTreeClassifier(**params, random_state=42) if is_classifier else DecisionTreeRegressor(**params, random_state=42)\n",
        "    elif model_type == 'RandomForest':\n",
        "        model = RandomForestClassifier(**params, random_state=42) if is_classifier else RandomForestRegressor(**params, random_state=42)\n",
        "    elif model_type == 'SVM':\n",
        "        model = SVC(**params, random_state=42) if is_classifier else SVR(**params)\n",
        "    elif model_type == 'XGBoost':\n",
        "        model = xgb.XGBClassifier(**params, random_state=42) if is_classifier else xgb.XGBRegressor(**params, random_state=42)\n",
        "    elif model_type == 'LightGBM':\n",
        "        if is_classifier:\n",
        "            model = lgb.LGBMClassifier(**params, random_state=42)\n",
        "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='logloss', callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
        "        else:\n",
        "            model = lgb.LGBMRegressor(**params, random_state=42)\n",
        "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='rmse', callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
        "        y_pred = model.predict(X_val)\n",
        "        if is_classifier:\n",
        "            accuracy = accuracy_score(y_val, y_pred)\n",
        "            precision = precision_score(y_val, y_pred, average='weighted', zero_division=0)\n",
        "            recall = recall_score(y_val, y_pred, average='weighted', zero_division=0)\n",
        "            f1 = f1_score(y_val, y_pred, average='weighted', zero_division=0)\n",
        "            return model, accuracy, precision, recall, f1\n",
        "        else:\n",
        "            mse = mean_squared_error(y_val, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(y_val, y_pred)\n",
        "            r2 = r2_score(y_val, y_pred)\n",
        "            return model, mse, rmse, mae, r2\n",
        "    elif model_type == 'CatBoost':\n",
        "        model = CatBoostClassifier(**params, random_seed=42, silent=True) if is_classifier else CatBoostRegressor(**params, random_seed=42, silent=True)\n",
        "    elif model_type == 'KNN':\n",
        "        model = KNeighborsClassifier(**params) if is_classifier else KNeighborsRegressor(**params)\n",
        "\n",
        "    # 모델 학습 및 예측\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # 분류 모델 평가\n",
        "    if is_classifier:\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        precision = precision_score(y_val, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_val, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_val, y_pred, average='weighted', zero_division=0)\n",
        "        return model, accuracy, precision, recall, f1\n",
        "    # 회귀 모델 평가\n",
        "    else:\n",
        "        mse = mean_squared_error(y_val, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y_val, y_pred)\n",
        "        r2 = r2_score(y_val, y_pred)\n",
        "        return model, mse, rmse, mae, r2\n",
        "\n",
        "# 모델 학습 및 평가 함수 정의\n",
        "def train_and_evaluate_models(model_type, param_grid_regressor, param_grid_classifier):\n",
        "    # 데이터프레임 복사\n",
        "    train_df_copy = train_df.copy()\n",
        "    predict_df_copy = predict_df.copy()\n",
        "    print(f\"  - 데이터프레임을 복사하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "    X_train_stroke = train_df_copy[features_stroke]\n",
        "    X_train_penalty = train_df_copy[features_penalty]\n",
        "    X_train_putt = train_df_copy[features_putt]\n",
        "    X_train_fw_hit = train_df_copy[train_df_copy['par'] != 3][features_fw_hit]\n",
        "\n",
        "    y_train_stroke = train_df_copy['stroke']\n",
        "    y_train_penalty = train_df_copy['penalty']\n",
        "    y_train_putt = train_df_copy['putt']\n",
        "    y_train_fw_hit = train_df_copy.loc[train_df_copy['par'] != 3, 'fw_hit']\n",
        "\n",
        "    # K-Fold 교차 검증 설정\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    print(f\"  - K-Fold 교차 검증을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "    model_names = ['Stroke', 'Penalty', 'Putt', 'FW_Hit']\n",
        "    X_trains = [X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit]\n",
        "    y_trains = [y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit]\n",
        "    param_grids = [param_grid_regressor, param_grid_regressor, param_grid_regressor, param_grid_classifier]\n",
        "    is_classifier = [False, False, False, True]\n",
        "\n",
        "    best_params_dict = {}\n",
        "    evaluation_results = {}\n",
        "    train_valid_scores = {}\n",
        "\n",
        "    for model_name, X_train, y_train, param_grid, classifier in zip(model_names, X_trains, y_trains, param_grids, is_classifier):\n",
        "        print(f\"\\n  - {model_name} 모델을 학습 및 평가합니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "        model, best_params, *metrics, metric_names = evaluate_model_with_kfold(X_train, y_train, param_grid, model_name.capitalize(), model_type=model_type, is_classifier=classifier)\n",
        "\n",
        "        # 평가 결과 저장\n",
        "        results[model_name][model_type] = {'최적 파라미터': best_params, **dict(zip(metric_names, metrics))}\n",
        "        save_model(model, model_type, model_name, eval(f'features_{model_name.lower()}'))\n",
        "\n",
        "        best_params_dict[model_name] = best_params\n",
        "        evaluation_results[model_name] = dict(zip(metric_names, metrics))\n",
        "\n",
        "        # 평가 결과를 파일로 저장\n",
        "        results_filename = f\"{model_file_path}/{model_type}_{model_name}_evaluation.json\"\n",
        "        with open(results_filename, 'w') as f:\n",
        "            json.dump(evaluation_results[model_name], f)\n",
        "        print(f\"  - 평가 결과를 '{results_filename}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "        # 최적 파라미터 저장\n",
        "        params_filename = f\"{model_file_path}/{model_type}_{model_name}_params.json\"\n",
        "        with open(params_filename, 'w') as f:\n",
        "            json.dump(best_params_dict[model_name], f)\n",
        "        print(f\"  - 최적 파라미터를 '{params_filename}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "        # 최적 파라미터로 모델 학습 후 성능 비교\n",
        "        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "        train_score, valid_score = print_train_valid_scores(model, X_train_split, y_train_split, X_val_split, y_val_split)\n",
        "        train_valid_scores[model_name] = {'훈련 데이터 점수': train_score, '검증 데이터 점수': valid_score}\n",
        "\n",
        "        # 훈련 및 검증 데이터 점수 저장\n",
        "        scores_filename = f\"{model_file_path}/{model_type}_{model_name}_scores.json\"\n",
        "        with open(scores_filename, 'w') as f:\n",
        "            json.dump(train_valid_scores[model_name], f)\n",
        "        print(f\"  - 훈련 및 검증 데이터 점수를 '{scores_filename}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "        print(F\"\\n  - {model_name} 모델의 훈련 및 검증 데이터의 점수:\")\n",
        "        print(f\"    - 훈련 데이터 점수: {train_score}\")\n",
        "        print(f\"    - 검증 데이터 점수: {valid_score}\")\n",
        "\n",
        "    print(f\"\\n  - {model_type} 모델 학습 및 평가가 완료되었습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "    print(\"\\n  - 각 변수별 최적 파라미터:\")\n",
        "    for model_name, best_params in best_params_dict.items():\n",
        "        print(f\"    - {model_name}: {best_params}\")\n",
        "\n",
        "    print(\"\\n  - 모델 평가 결과:\")\n",
        "    for model_name, eval_result in evaluation_results.items():\n",
        "        print(f\"    - {model_name}:\")\n",
        "        for metric_name, metric_value in eval_result.items():\n",
        "            print(f\"      - {metric_name.upper()}: {metric_value}\")\n",
        "\n",
        "    print(\"\\n  - 모델 훈련 및 검증 데이터 점수:\")\n",
        "    for model_name, scores in train_valid_scores.items():\n",
        "        print(f\"    - {model_name}:\")\n",
        "        for score_type, score_value in scores.items():\n",
        "            print(f\"      - {score_type}: {score_value}\")\n",
        "\n",
        "    return best_params_dict, evaluation_results, train_valid_scores\n",
        "\n",
        "def print_train_valid_scores(model, X_train, y_train, X_valid, y_valid):\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        # 분류 모델의 경우\n",
        "        train_score = accuracy_score(y_train, model.predict(X_train))\n",
        "        valid_score = accuracy_score(y_valid, model.predict(X_valid))\n",
        "    else:\n",
        "        # 회귀 모델의 경우\n",
        "        train_score = model.score(X_train, y_train)\n",
        "        valid_score = model.score(X_valid, y_valid)\n",
        "\n",
        "    return train_score, valid_score\n",
        "\n",
        "print(f\"  - 모델 생성 및 학습, 평가 함수 정의를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qveNd_z4EQDZ",
      "metadata": {
        "id": "qveNd_z4EQDZ"
      },
      "source": [
        "### 02-1-3. 시각화 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "QGfcSYTsRh3L",
      "metadata": {
        "id": "QGfcSYTsRh3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0b367e-3c08-4b24-bc18-989a22681191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02-1-3. 시각화 함수 정의\n",
            "  - 학습과 예측에 사용할 변수와 예측할 변수를 설정하였습니다. (2024-08-10 18:15:34)\n",
            "  - 시각화 함수 정의를 완료하였습니다. (2024-08-10 18:15:34)\n"
          ]
        }
      ],
      "source": [
        "# 02-1-3. 시각화 함수 정의 (240701)\n",
        "print(\"02-1-3. 시각화 함수 정의\")\n",
        "\n",
        "# 모델 시각화 함수 정의\n",
        "def plot_predictions(y_true, y_pred, title, xlabel, ylabel):\n",
        "    plt.scatter(y_true, y_pred, alpha=0.1)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')\n",
        "\n",
        "# 모델 예측 결과 시각화 함수 정의\n",
        "def visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                          X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                          y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit):\n",
        "    y_pred_stroke = model_stroke.predict(X_train_stroke)\n",
        "    y_pred_penalty = model_penalty.predict(X_train_penalty)\n",
        "    y_pred_putt = model_putt.predict(X_train_putt)\n",
        "    y_pred_fw_hit = model_fw_hit.predict(X_train_fw_hit)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plot_predictions(y_train_stroke, y_pred_stroke, 'Stroke Prediction', 'Actual Stroke', 'Predicted Stroke')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plot_predictions(y_train_penalty, y_pred_penalty, 'Penalty Prediction', 'Actual Penalty', 'Predicted Penalty')\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plot_predictions(y_train_putt, y_pred_putt, 'Putt Prediction', 'Actual Putt', 'Predicted Putt')\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    y_pred_fw_hit_class = (y_pred_fw_hit > 0.5).astype(int)  # 이진 분류로 변환\n",
        "    cm = confusion_matrix(y_train_fw_hit, y_pred_fw_hit_class)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(ax=plt.gca())\n",
        "    plt.title(\"FW Hit Prediction - Confusion Matrix\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# SHAP 값 계산 및 시각화 함수 정의\n",
        "def plot_shap_summary(model, X_test, title, subplot, plot_type=\"bar\"):\n",
        "    explainer = shap.Explainer(model)\n",
        "    shap_values = explainer(X_test)\n",
        "    plt.subplot(2, 2, subplot)\n",
        "    shap.summary_plot(shap_values, X_test, plot_type=plot_type, show=False)\n",
        "    plt.title(title, fontsize=15)\n",
        "    plt.xticks(fontsize=10)\n",
        "    plt.yticks(fontsize=10)\n",
        "\n",
        "# SHAP 값 시각화 함수 정의\n",
        "def visualize_shap_values(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                          X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit):\n",
        "    plt.figure(figsize=(20, 14))\n",
        "    plot_shap_summary(model_stroke, X_train_stroke, 'Stroke SHAP Values', 1, \"bar\")\n",
        "    plot_shap_summary(model_penalty, X_train_penalty, 'Penalty SHAP Values', 2, \"bar\")\n",
        "    plot_shap_summary(model_putt, X_train_putt, 'Putt SHAP Values', 3, \"bar\")\n",
        "    plot_shap_summary(model_fw_hit, X_train_fw_hit, 'FW Hit SHAP Values', 4, \"bar\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(20, 14))\n",
        "    plot_shap_summary(model_stroke, X_train_stroke, 'Stroke SHAP Values', 1, \"dot\")\n",
        "    plot_shap_summary(model_penalty, X_train_penalty, 'Penalty SHAP Values', 2, \"dot\")\n",
        "    plot_shap_summary(model_putt, X_train_putt, 'Putt SHAP Values', 3, \"dot\")\n",
        "    plot_shap_summary(model_fw_hit, X_train_fw_hit, 'FW Hit SHAP Values', 4, \"dot\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 실제 예측 수행 함수 정의\n",
        "def predict_and_update(model, features, target_col, df, additional_updates=None):\n",
        "    \"\"\"\n",
        "    주어진 모델과 피처를 사용하여 예측을 수행하고 데이터프레임을 업데이트합니다.\n",
        "\n",
        "    Parameters:\n",
        "    model: 예측 모델\n",
        "    features: 예측에 사용되는 피처 목록\n",
        "    target_col: 예측 결과를 저장할 대상 열\n",
        "    df: 예측을 수행할 데이터프레임\n",
        "    additional_updates: 추가로 업데이트할 함수 리스트 (Optional)\n",
        "    \"\"\"\n",
        "    X_predict = df[features].dropna()\n",
        "    predictions = model.predict(X_predict)\n",
        "    df.loc[X_predict.index, target_col] = predictions\n",
        "\n",
        "    if additional_updates:\n",
        "        for update_func in additional_updates:\n",
        "            update_func(df)\n",
        "\n",
        "def update_score_minus_stroke(df):\n",
        "    df['score_minus_stroke'] = df['score'] - df['stroke']\n",
        "\n",
        "def update_score_minus_stroke_minus_penalty(df):\n",
        "    df['score_minus_stroke_minus_penalty'] = df['score_minus_stroke'] - df['penalty']\n",
        "\n",
        "# 학습과 예측에 사용할 변수와 예측할 변수 설정\n",
        "features_stroke = ['no', 'hole_no', 'par', 'month', 'hour', 'season', 'course_type_b9', 'score']\n",
        "features_penalty = ['no', 'hole_no', 'par', 'month', 'hour', 'season', 'course_type_b9', 'score', 'stroke', 'score_minus_stroke']\n",
        "features_putt = ['no', 'hole_no', 'par', 'month', 'hour', 'season', 'course_type_b9', 'score', 'stroke', 'penalty', 'score_minus_stroke_minus_penalty']\n",
        "features_fw_hit = ['no', 'hole_no', 'par', 'month', 'hour', 'season', 'course_type_b9', 'stroke', 'penalty', 'putt']\n",
        "print(f\"  - 학습과 예측에 사용할 변수와 예측할 변수를 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 평가 결과 저장할 딕셔너리 생성\n",
        "results = {\n",
        "    'Stroke': {},\n",
        "    'Penalty': {},\n",
        "    'Putt': {},\n",
        "    'FW_Hit': {}\n",
        "}\n",
        "\n",
        "print(f\"  - 시각화 함수 정의를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gCbBVqgQimIl",
      "metadata": {
        "id": "gCbBVqgQimIl"
      },
      "source": [
        "## 02-2. 의사결정 트리 (Decision Tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MW6_qUO9JI3z",
      "metadata": {
        "id": "MW6_qUO9JI3z"
      },
      "outputs": [],
      "source": [
        "# 02-2-1. 의사결정 트리 모델을 이용한 모델 생성, 학습 및 평가 (240628)\n",
        "print(\"02-2-1. 의사결정 트리 모델을 이용한 모델 생성, 학습 및 평가\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝\n",
        "param_grid_regressor = {\n",
        "    'max_depth': [2, 3, 4, 5],  # 트리의 최대 깊이. 너무 깊으면 과적합 위험이 있음.\n",
        "    'min_samples_leaf': [2, 3, 4],  # 리프 노드가 되기 위한 최소 샘플 수. 너무 낮으면 과적합 위험이 있음.\n",
        "    'min_samples_split': [2, 3, 4]  # 분할하기 위한 최소 샘플 수. 너무 낮으면 과적합 위험이 있음.\n",
        "}\n",
        "param_grid_classifier = {\n",
        "    'max_depth': [2, 3, 4, 5],\n",
        "    'min_samples_leaf': [2, 3, 4],\n",
        "    'min_samples_split': [2, 3, 4]\n",
        "}\n",
        "print(f\"  - 하이퍼파라미터 튜닝을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 의사결정 트리 모델 학습 및 평가\n",
        "train_and_evaluate_models('DecisionTree', param_grid_regressor, param_grid_classifier)\n",
        "\n",
        "print(f\"\\n  - 모델 학습 및 평가를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2yLd9jFfJ3wG",
      "metadata": {
        "id": "2yLd9jFfJ3wG"
      },
      "outputs": [],
      "source": [
        "# 02-2-2. 의사결정 트리 모델 시각화 (240628)\n",
        "print(\"02-2-2. 의사결정 트리 모델 시각화\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, _ = load_model('DecisionTree', 'Stroke')\n",
        "model_penalty, _ = load_model('DecisionTree', 'Penalty')\n",
        "model_putt, _ = load_model('DecisionTree', 'Putt')\n",
        "model_fw_hit, _ = load_model('DecisionTree', 'FW_Hit')\n",
        "\n",
        "# 모델 예측 결과 시각화\n",
        "visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                      y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit)\n",
        "\n",
        "print(f\"  - 시각화를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9jJYA1RgJ5Fq",
      "metadata": {
        "id": "9jJYA1RgJ5Fq"
      },
      "outputs": [],
      "source": [
        "# 02-2-3. 의사결정 트리 모델을 이용한 실제 예측 수행 (240628)\n",
        "print(\"02-2-3. 의사결정 트리 모델을 이용한 실제 예측 수행\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, features_stroke = load_model('DecisionTree', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('DecisionTree', 'Penalty')\n",
        "model_putt, features_putt = load_model('DecisionTree', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('DecisionTree', 'FW_Hit')\n",
        "\n",
        "# predict_df_copy 변수 초기화\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# stroke 예측 및 업데이트\n",
        "predict_and_update(model_stroke, features_stroke, 'stroke', predict_df_copy, [update_score_minus_stroke])\n",
        "\n",
        "# penalty 예측 및 업데이트 (stroke 포함)\n",
        "predict_and_update(model_penalty, features_penalty, 'penalty', predict_df_copy, [update_score_minus_stroke_minus_penalty])\n",
        "\n",
        "# putt 예측 및 업데이트 (stroke와 penalty 포함)\n",
        "predict_and_update(model_putt, features_putt, 'putt', predict_df_copy)\n",
        "\n",
        "# fw_hit 예측 및 업데이트 (stroke, penalty, putt 포함)\n",
        "predict_and_update(model_fw_hit, features_fw_hit, 'fw_hit', predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h3qPgYHdj1gk",
      "metadata": {
        "id": "h3qPgYHdj1gk"
      },
      "source": [
        "## 02-3. 랜덤 포레스트 (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vjFO2TKJ9_Fy",
      "metadata": {
        "id": "vjFO2TKJ9_Fy"
      },
      "outputs": [],
      "source": [
        "# 02-3-1. 랜덤 포레스트 모델을 이용한 모델 생성, 학습 및 평가 (240628)\n",
        "print(\"02-3-1. 랜덤 포레스트 모델을 이용한 모델 생성, 학습 및 평가\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝\n",
        "param_grid_regressor = {\n",
        "    'max_depth': [2, 3, 5, 7],  # 트리의 최대 깊이. 너무 깊으면 과적합 위험이 있음.\n",
        "    'min_samples_leaf': [2, 3, 4, 5],  # 리프 노드가 되기 위한 최소 샘플 수. 너무 낮으면 과적합 위험이 있음.\n",
        "    'min_samples_split': [5, 10, 15, 20],  # 분할하기 위한 최소 샘플 수. 너무 낮으면 과적합 위험이 있음.\n",
        "    'n_estimators': [50, 100, 200]  # 트리의 개수. 너무 많으면 과적합 위험이 있음.\n",
        "}\n",
        "param_grid_classifier = {\n",
        "    'max_depth': [2, 3, 5, 7],\n",
        "    'min_samples_leaf': [2, 3, 4, 5],\n",
        "    'min_samples_split': [5, 10, 15, 20],\n",
        "    'n_estimators': [50, 100, 200]\n",
        "}\n",
        "print(f\"  - 하이퍼파라미터 튜닝을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 랜덤 포레스트 모델 학습 및 평가\n",
        "train_and_evaluate_models('RandomForest', param_grid_regressor, param_grid_classifier)\n",
        "\n",
        "print(f\"\\n  - 모델 학습 및 평가를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RGwVp7EmFJDK",
      "metadata": {
        "id": "RGwVp7EmFJDK"
      },
      "outputs": [],
      "source": [
        "# 02-3-2. 랜덤 포레스트 모델 시각화 (240628)\n",
        "print(\"02-3-2. 랜덤 포레스트 모델 시각화\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, _ = load_model('RandomForest', 'Stroke')\n",
        "model_penalty, _ = load_model('RandomForest', 'Penalty')\n",
        "model_putt, _ = load_model('RandomForest', 'Putt')\n",
        "model_fw_hit, _ = load_model('RandomForest', 'FW_Hit')\n",
        "\n",
        "# 모델 예측 결과 시각화\n",
        "visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                      y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit)\n",
        "\n",
        "print(f\"  - 시각화를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cc3U9GjvU92D",
      "metadata": {
        "id": "Cc3U9GjvU92D"
      },
      "outputs": [],
      "source": [
        "# 02-3-3. 랜덤 포레스트 모델을 이용한 실제 예측 수행 (240628)\n",
        "print(\"02-3-3. 랜덤 포레스트 모델을 이용한 실제 예측 수행\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, features_stroke = load_model('RandomForest', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('RandomForest', 'Penalty')\n",
        "model_putt, features_putt = load_model('RandomForest', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('RandomForest', 'FW_Hit')\n",
        "\n",
        "# predict_df_copy 변수 초기화\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# stroke 예측 및 업데이트\n",
        "predict_and_update(model_stroke, features_stroke, 'stroke', predict_df_copy, [update_score_minus_stroke])\n",
        "\n",
        "# penalty 예측 및 업데이트 (stroke 포함)\n",
        "predict_and_update(model_penalty, features_penalty, 'penalty', predict_df_copy, [update_score_minus_stroke_minus_penalty])\n",
        "\n",
        "# putt 예측 및 업데이트 (stroke와 penalty 포함)\n",
        "predict_and_update(model_putt, features_putt, 'putt', predict_df_copy)\n",
        "\n",
        "# fw_hit 예측 및 업데이트 (stroke, penalty, putt 포함)\n",
        "predict_and_update(model_fw_hit, features_fw_hit, 'fw_hit', predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E4c7598skq4a",
      "metadata": {
        "id": "E4c7598skq4a"
      },
      "source": [
        "## 02-4. 서포트 벡터 머신 (SVM; Support Vector Machine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7yGW87N21blV",
      "metadata": {
        "id": "7yGW87N21blV"
      },
      "outputs": [],
      "source": [
        "# 02-4-1. 서포트 벡터 머신 모델을 이용한 모델 생성, 학습 및 평가 (240628)\n",
        "print(\"02-4-1. 서포트 벡터 머신 모델을 이용한 모델 생성, 학습 및 평가\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝\n",
        "param_grid_regressor = {\n",
        "    'C': [0.1, 1, 2, 5],  # Regularization parameter. 너무 크면 과적합 위험이 있음.\n",
        "    'epsilon': [0.2, 0.5, 0.75, 1.0],  # Epsilon in the epsilon-SVR model. 너무 작으면 과적합 위험이 있음.\n",
        "    'kernel': ['linear', 'poly', 'rbf']  # 데이터의 변환 방식. 고차원 커널은 과적합 위험이 있음.\n",
        "}\n",
        "param_grid_classifier = {\n",
        "    'C': [0.1, 1, 2, 5],\n",
        "    'kernel': ['linear', 'poly', 'rbf']\n",
        "}\n",
        "print(f\"  - 하이퍼파라미터 튜닝을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 서포트 벡터 머신 모델 학습 및 평가\n",
        "train_and_evaluate_models('SVM', param_grid_regressor, param_grid_classifier)\n",
        "\n",
        "print(f\"\\n  - 모델 학습 및 평가를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C6L65asnW-bG",
      "metadata": {
        "id": "C6L65asnW-bG"
      },
      "outputs": [],
      "source": [
        "# 02-4-2. 서포트 벡터 머신 모델 시각화 (240628)\n",
        "print(\"02-4-2. 서포트 벡터 머신 모델 시각화\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, _ = load_model('SVM', 'Stroke')\n",
        "model_penalty, _ = load_model('SVM', 'Penalty')\n",
        "model_putt, _ = load_model('SVM', 'Putt')\n",
        "model_fw_hit, _ = load_model('SVM', 'FW_Hit')\n",
        "\n",
        "# 모델 예측 결과 시각화\n",
        "visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                      y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit)\n",
        "\n",
        "print(f\"  - 시각화를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WNfSS3sZcaVX",
      "metadata": {
        "id": "WNfSS3sZcaVX"
      },
      "outputs": [],
      "source": [
        "# 02-4-3. 서포트 벡터 머신 모델을 이용한 실제 예측 수행 (240628)\n",
        "print(\"02-4-3. 서포트 벡터 머신 모델을 이용한 실제 예측 수행\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, features_stroke = load_model('SVM', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('SVM', 'Penalty')\n",
        "model_putt, features_putt = load_model('SVM', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('SVM', 'FW_Hit')\n",
        "\n",
        "# predict_df_copy 변수 초기화\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# stroke 예측 및 업데이트\n",
        "predict_and_update(model_stroke, features_stroke, 'stroke', predict_df_copy, [update_score_minus_stroke])\n",
        "\n",
        "# penalty 예측 및 업데이트 (stroke 포함)\n",
        "predict_and_update(model_penalty, features_penalty, 'penalty', predict_df_copy, [update_score_minus_stroke_minus_penalty])\n",
        "\n",
        "# putt 예측 및 업데이트 (stroke와 penalty 포함)\n",
        "predict_and_update(model_putt, features_putt, 'putt', predict_df_copy)\n",
        "\n",
        "# fw_hit 예측 및 업데이트 (stroke, penalty, putt 포함)\n",
        "predict_and_update(model_fw_hit, features_fw_hit, 'fw_hit', predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bgjfle8Mux5L",
      "metadata": {
        "id": "bgjfle8Mux5L"
      },
      "source": [
        "## 02-5. XGBoost (eXtreme Gradient Boosting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r9NMSHR--TuS",
      "metadata": {
        "id": "r9NMSHR--TuS"
      },
      "outputs": [],
      "source": [
        "# 02-5-1. XGBoost 모델을 이용한 모델 생성, 학습 및 평가 (240628)\n",
        "print(\"02-5-1. XGBoost 모델을 이용한 모델 생성, 학습 및 평가\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝\n",
        "param_grid_regressor = {\n",
        "    'colsample_bytree': [0.1, 0.5, 1.0],  # 트리를 구성할 때 사용할 특징의 비율. 너무 높으면 과적합 위험이 있음.\n",
        "    'gamma': [1e-9, 0.1, 0.5],  # 노드 분할에 필요한 최소 손실 감소. 너무 작으면 과적합 위험이 있음.\n",
        "    'learning_rate': [0.01, 0.10, 0.15],  # 학습률. 너무 높으면 과적합 위험이 있음.\n",
        "    'max_depth': [2, 3, 4, 5],  # 트리의 최대 깊이. 너무 깊으면 과적합 위험이 있음.\n",
        "    'min_child_weight': [0, 5, 10, 15],  # 리프 노드가 되기 위한 최소 가중치 합. 너무 작으면 과적합 위험이 있음.\n",
        "    'n_estimators': [100, 500, 1000],  # 부스팅 단위의 개수. 너무 많으면 과적합 위험이 있음.\n",
        "    'subsample': [0.1, 0.25, 0.5, 0.75, 1.0]  # 트리를 구성할 때 사용할 데이터의 비율. 너무 높으면 과적합 위험이 있음.\n",
        "}\n",
        "param_grid_classifier = {\n",
        "    'colsample_bytree': [0.1, 0.5, 1.0],\n",
        "    'gamma': [1e-9, 0.1, 0.5],\n",
        "    'learning_rate': [0.01, 0.1, 0.15],\n",
        "    'max_depth': [2, 3, 4, 5],\n",
        "    'min_child_weight': [0, 5, 10, 15],\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "    'subsample': [0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "}\n",
        "print(f\"  - 하이퍼파라미터 튜닝을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# XGBoost 모델 학습 및 평가\n",
        "train_and_evaluate_models('XGBoost', param_grid_regressor, param_grid_classifier)\n",
        "\n",
        "print(f\"\\n  - 모델 학습 및 평가를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bJ99LkGEv8eV",
      "metadata": {
        "id": "bJ99LkGEv8eV"
      },
      "outputs": [],
      "source": [
        "# 02-5-2. XGBoost 모델 시각화 (240628)\n",
        "print(\"02-5-2. XGBoost 모델 시각화\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, _ = load_model('XGBoost', 'Stroke')\n",
        "model_penalty, _ = load_model('XGBoost', 'Penalty')\n",
        "model_putt, _ = load_model('XGBoost', 'Putt')\n",
        "model_fw_hit, _ = load_model('XGBoost', 'FW_Hit')\n",
        "\n",
        "# 모델 예측 결과 시각화\n",
        "visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                      y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit)\n",
        "\n",
        "# SHAP 값 시각화\n",
        "visualize_shap_values(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit)\n",
        "\n",
        "print(f\"  - 시각화를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8tVGG3nlv8vS",
      "metadata": {
        "id": "8tVGG3nlv8vS"
      },
      "outputs": [],
      "source": [
        "# 02-5-3. XGBoost 모델을 이용한 실제 예측 수행 (240628)\n",
        "print(\"02-5-3. XGBoost 모델을 이용한 실제 예측 수행\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, features_stroke = load_model('XGBoost', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('XGBoost', 'Penalty')\n",
        "model_putt, features_putt = load_model('XGBoost', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('XGBoost', 'FW_Hit')\n",
        "\n",
        "# predict_df_copy 변수 초기화\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# stroke 예측 및 업데이트\n",
        "predict_and_update(model_stroke, features_stroke, 'stroke', predict_df_copy, [update_score_minus_stroke])\n",
        "\n",
        "# penalty 예측 및 업데이트 (stroke 포함)\n",
        "predict_and_update(model_penalty, features_penalty, 'penalty', predict_df_copy, [update_score_minus_stroke_minus_penalty])\n",
        "\n",
        "# putt 예측 및 업데이트 (stroke와 penalty 포함)\n",
        "predict_and_update(model_putt, features_putt, 'putt', predict_df_copy)\n",
        "\n",
        "# fw_hit 예측 및 업데이트 (stroke, penalty, putt 포함)\n",
        "predict_and_update(model_fw_hit, features_fw_hit, 'fw_hit', predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1EJ9ZctGvO1G",
      "metadata": {
        "id": "1EJ9ZctGvO1G"
      },
      "source": [
        "## 02-6. LightGBM (Light Gradient Boosting Machine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kP9O_FSXw7_x",
      "metadata": {
        "id": "kP9O_FSXw7_x"
      },
      "outputs": [],
      "source": [
        "# 02-6-1. LightGBM 모델을 이용한 모델 생성, 학습 및 평가 (240628)\n",
        "print(\"02-6-1. LightGBM 모델을 이용한 모델 생성, 학습 및 평가\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝\n",
        "param_grid_regressor = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15],  # 학습률. 너무 높으면 과적합 위험이 있음.\n",
        "    'max_depth': [2, 3, 4, 5],  # 트리의 최대 깊이. 너무 깊으면 과적합 위험이 있음.\n",
        "    'min_child_samples': [20, 30, 50],  # 리프 노드가 되기 위한 최소 샘플 수. 너무 작으면 과적합 위험이 있음\n",
        "    'n_estimators': [100, 250, 500],  # 트리의 개수. 너무 많으면 과적합 위험이 있음.\n",
        "    'num_leaves': [32]  # 하나의 트리가 가질 수 있는 최대 리프의 수.\n",
        "}\n",
        "param_grid_classifier = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
        "    'max_depth': [2, 3, 4, 5],\n",
        "    'min_child_samples': [20, 30, 50],\n",
        "    'n_estimators': [100, 250, 500],\n",
        "    'num_leaves': [32]\n",
        "}\n",
        "print(f\"  - 하이퍼파라미터 튜닝을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# LightGBM 모델 학습 및 평가\n",
        "train_and_evaluate_models('LightGBM', param_grid_regressor, param_grid_classifier)\n",
        "\n",
        "print(f\"\\n  - 모델 학습 및 평가를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M7VeIVj1j2hX",
      "metadata": {
        "id": "M7VeIVj1j2hX"
      },
      "outputs": [],
      "source": [
        "# 02-6-2. LightGBM 모델 시각화 (240628)\n",
        "print(\"02-6-2. LightGBM 모델 시각화\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, _ = load_model('LightGBM', 'Stroke')\n",
        "model_penalty, _ = load_model('LightGBM', 'Penalty')\n",
        "model_putt, _ = load_model('LightGBM', 'Putt')\n",
        "model_fw_hit, _ = load_model('LightGBM', 'FW_Hit')\n",
        "\n",
        "# 모델 예측 결과 시각화\n",
        "visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                      y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit)\n",
        "\n",
        "# SHAP 값 시각화\n",
        "visualize_shap_values(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit)\n",
        "\n",
        "print(f\"  - 시각화를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BTRG_v3N9nUM",
      "metadata": {
        "id": "BTRG_v3N9nUM"
      },
      "outputs": [],
      "source": [
        "# 02-6-3. LightGBM 모델을 이용한 실제 예측 수행 (240628)\n",
        "print(\"02-6-3. LightGBM 모델을 이용한 실제 예측 수행\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, features_stroke = load_model('LightGBM', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('LightGBM', 'Penalty')\n",
        "model_putt, features_putt = load_model('LightGBM', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('LightGBM', 'FW_Hit')\n",
        "\n",
        "# predict_df_copy 변수 초기화\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# stroke 예측 및 업데이트\n",
        "predict_and_update(model_stroke, features_stroke, 'stroke', predict_df_copy, [update_score_minus_stroke])\n",
        "\n",
        "# penalty 예측 및 업데이트 (stroke 포함)\n",
        "predict_and_update(model_penalty, features_penalty, 'penalty', predict_df_copy, [update_score_minus_stroke_minus_penalty])\n",
        "\n",
        "# putt 예측 및 업데이트 (stroke와 penalty 포함)\n",
        "predict_and_update(model_putt, features_putt, 'putt', predict_df_copy)\n",
        "\n",
        "# fw_hit 예측 및 업데이트 (stroke, penalty, putt 포함)\n",
        "predict_and_update(model_fw_hit, features_fw_hit, 'fw_hit', predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V3yjw-eHxOsw",
      "metadata": {
        "id": "V3yjw-eHxOsw"
      },
      "source": [
        "## 02-7. CatBoost (Category Boosting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vgtvc2cKb2DR",
      "metadata": {
        "id": "Vgtvc2cKb2DR"
      },
      "outputs": [],
      "source": [
        "# 02-7-1. CatBoost 모델을 이용한 모델 생성, 학습 및 평가 (240628)\n",
        "print(\"02-7-1. CatBoost 모델을 이용한 모델 생성, 학습 및 평가\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝\n",
        "param_grid_regressor = {\n",
        "    'depth': [2, 4, 5],  # 각 트리의 깊이. 너무 깊으면 과적합 위험이 있음.\n",
        "    'iterations': [50, 100, 250, 500, 750, 1000],  # 부스팅 반복 횟수. 너무 많으면 과적합 위험이 있음.\n",
        "    'l2_leaf_reg': [1e-6, 1e-3, 1, 10],  # L2 정규화 계수. 너무 작으면 과적합 위험이 있음.\n",
        "    'learning_rate': [0.01, 0.05, 0.10, 0.15]  # 학습률. 너무 높으면 과적합 위험이 있음.\n",
        "}\n",
        "param_grid_classifier = {\n",
        "    'depth': [2, 4, 5],\n",
        "    'iterations': [50, 100, 250, 500, 750, 1000],\n",
        "    'l2_leaf_reg': [1e-6, 1e-3, 1, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.10, 0.15]\n",
        "}\n",
        "print(f\"  - 하이퍼파라미터 튜닝을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# CatBoost 모델 학습 및 평가\n",
        "train_and_evaluate_models('CatBoost', param_grid_regressor, param_grid_classifier)\n",
        "\n",
        "print(f\"\\n  - 모델 학습 및 평가를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bD-M3y-Jpa8p",
      "metadata": {
        "id": "bD-M3y-Jpa8p"
      },
      "outputs": [],
      "source": [
        "# 02-7-2. CatBoost 모델 시각화 (240628)\n",
        "print(\"02-7-2. CatBoost 모델 시각화\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, _ = load_model('CatBoost', 'Stroke')\n",
        "model_penalty, _ = load_model('CatBoost', 'Penalty')\n",
        "model_putt, _ = load_model('CatBoost', 'Putt')\n",
        "model_fw_hit, _ = load_model('CatBoost', 'FW_Hit')\n",
        "\n",
        "# 모델 예측 결과 시각화\n",
        "visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                      y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit)\n",
        "\n",
        "# SHAP 값 시각화\n",
        "visualize_shap_values(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit)\n",
        "\n",
        "print(f\"  - 시각화를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4UT0OzZj2z-p",
      "metadata": {
        "id": "4UT0OzZj2z-p"
      },
      "outputs": [],
      "source": [
        "# 02-7-3. CatBoost 모델을 이용한 실제 예측 수행 (240628)\n",
        "print(\"02-7-3. CatBoost 모델을 이용한 실제 예측 수행\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, features_stroke = load_model('CatBoost', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('CatBoost', 'Penalty')\n",
        "model_putt, features_putt = load_model('CatBoost', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('CatBoost', 'FW_Hit')\n",
        "\n",
        "# predict_df_copy 변수 초기화\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# stroke 예측 및 업데이트\n",
        "predict_and_update(model_stroke, features_stroke, 'stroke', predict_df_copy, [update_score_minus_stroke])\n",
        "\n",
        "# penalty 예측 및 업데이트 (stroke 포함)\n",
        "predict_and_update(model_penalty, features_penalty, 'penalty', predict_df_copy, [update_score_minus_stroke_minus_penalty])\n",
        "\n",
        "# putt 예측 및 업데이트 (stroke와 penalty 포함)\n",
        "predict_and_update(model_putt, features_putt, 'putt', predict_df_copy)\n",
        "\n",
        "# fw_hit 예측 및 업데이트 (stroke, penalty, putt 포함)\n",
        "predict_and_update(model_fw_hit, features_fw_hit, 'fw_hit', predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9o_HXkTg0Y-0",
      "metadata": {
        "id": "9o_HXkTg0Y-0"
      },
      "source": [
        "## 02-8. K-최근접 이웃 (KNN; K-Nearest Neighbors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VO2vNx2Db4YB",
      "metadata": {
        "id": "VO2vNx2Db4YB"
      },
      "outputs": [],
      "source": [
        "# 02-8-1. K-Nearest Neighbors 모델을 이용한 모델 생성, 학습 및 평가 (240628)\n",
        "print(\"02-8-1. K-Nearest Neighbors 모델을 이용한 모델 생성, 학습 및 평가\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝\n",
        "param_grid_regressor = {\n",
        "    'n_neighbors': [3, 4, 5, 6, 7, 8],  # 이웃의 수. 너무 작으면 과적합 위험이 있음.\n",
        "    'p': [1, 2],  # 거리 측정 방식. 1: 맨해튼 거리, 2: 유클리드 거리.\n",
        "#    'weights': ['uniform', 'distance']  # 가중치 함수. 'uniform'은 동일한 가중치, 'distance'는 거리의 역수에 비례한 가중치를 사용.\n",
        "    'weights': ['uniform']  # 가중치 함수. 'uniform'은 동일한 가중치, 'distance'는 거리의 역수에 비례한 가중치를 사용.\n",
        "}\n",
        "param_grid_classifier = {\n",
        "    'n_neighbors': [3, 4, 5, 6, 7, 8],\n",
        "    'p': [1, 2],\n",
        "#    'weights': ['uniform', 'distance']\n",
        "    'weights': ['uniform']\n",
        "}\n",
        "print(f\"  - 하이퍼파라미터 튜닝을 설정하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# KNN 모델 학습 및 평가\n",
        "train_and_evaluate_models('KNN', param_grid_regressor, param_grid_classifier)\n",
        "\n",
        "print(f\"\\n  - 모델 학습 및 평가를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dOWg9pic4Q_R",
      "metadata": {
        "id": "dOWg9pic4Q_R"
      },
      "outputs": [],
      "source": [
        "# 02-8-2. K-Nearest Neighbors 모델 시각화 (240628)\n",
        "print(\"02-8-2. K-Nearest Neighbors 모델 시각화\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, _ = load_model('KNN', 'Stroke')\n",
        "model_penalty, _ = load_model('KNN', 'Penalty')\n",
        "model_putt, _ = load_model('KNN', 'Putt')\n",
        "model_fw_hit, _ = load_model('KNN', 'FW_Hit')\n",
        "\n",
        "# 모델 예측 결과 시각화\n",
        "visualize_predictions(model_stroke, model_penalty, model_putt, model_fw_hit,\n",
        "                      X_train_stroke, X_train_penalty, X_train_putt, X_train_fw_hit,\n",
        "                      y_train_stroke, y_train_penalty, y_train_putt, y_train_fw_hit)\n",
        "\n",
        "print(f\"  - 시각화를 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OI5HmM7JqMND",
      "metadata": {
        "id": "OI5HmM7JqMND"
      },
      "outputs": [],
      "source": [
        "# 02-8-3. K-Nearest Neighbors 모델을 이용한 실제 예측 수행 (240628)\n",
        "print(\"02-8-3. K-Nearest Neighbors 모델을 이용한 실제 예측 수행\")\n",
        "\n",
        "# 모델 불러오기\n",
        "model_stroke, features_stroke = load_model('KNN', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('KNN', 'Penalty')\n",
        "model_putt, features_putt = load_model('KNN', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('KNN', 'FW_Hit')\n",
        "\n",
        "# predict_df_copy 변수 초기화\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# stroke 예측 및 업데이트\n",
        "predict_and_update(model_stroke, features_stroke, 'stroke', predict_df_copy, [update_score_minus_stroke])\n",
        "\n",
        "# penalty 예측 및 업데이트 (stroke 포함)\n",
        "predict_and_update(model_penalty, features_penalty, 'penalty', predict_df_copy, [update_score_minus_stroke_minus_penalty])\n",
        "\n",
        "# putt 예측 및 업데이트 (stroke와 penalty 포함)\n",
        "predict_and_update(model_putt, features_putt, 'putt', predict_df_copy)\n",
        "\n",
        "# fw_hit 예측 및 업데이트 (stroke, penalty, putt 포함)\n",
        "predict_and_update(model_fw_hit, features_fw_hit, 'fw_hit', predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q6hzvbBFECr0",
      "metadata": {
        "id": "q6hzvbBFECr0"
      },
      "source": [
        "# 03. 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_DxXo6xyMTR7",
      "metadata": {
        "id": "_DxXo6xyMTR7"
      },
      "outputs": [],
      "source": [
        "# 03-1. 모델 평가 결과 종합 및 저장 (240810)\n",
        "print(\"03-1. 모델 평가 결과 종합 및 저장\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "sub_directory_name = 'Output'\n",
        "output_file_name = 'gScore_Model_Evaluation_Results.parquet'\n",
        "output_file_path = os.path.join(base_path, sub_directory_name, output_file_name)\n",
        "\n",
        "# 모델 평가 결과 종합 및 저장\n",
        "model_types = ['DecisionTree', 'RandomForest', 'SVM', 'XGBoost', 'LightGBM', 'CatBoost', 'KNN']\n",
        "model_names = ['Stroke', 'Penalty', 'Putt', 'FW_Hit']\n",
        "results_dict = {}\n",
        "params_dict = {}\n",
        "scores_dict = {}\n",
        "\n",
        "for model_name in model_names:\n",
        "    for model_type in model_types:\n",
        "        # 평가 결과 로드\n",
        "        results_filename = f\"{model_file_path}/{model_type}_{model_name}_evaluation.json\"\n",
        "        if os.path.exists(results_filename):\n",
        "            with open(results_filename, 'r') as f:\n",
        "                metrics = json.load(f)\n",
        "                results_dict.setdefault(model_name, {}).update({model_type: metrics})\n",
        "\n",
        "        # 최적 파라미터 로드\n",
        "        params_filename = f\"{model_file_path}/{model_type}_{model_name}_params.json\"\n",
        "        if os.path.exists(params_filename):\n",
        "            with open(params_filename, 'r') as f:\n",
        "                params = json.load(f)\n",
        "                params_dict.setdefault(model_name, {}).update({model_type: params})\n",
        "\n",
        "        # 훈련 및 검증 데이터 점수 로드\n",
        "        scores_filename = f\"{model_file_path}/{model_type}_{model_name}_scores.json\"\n",
        "        if os.path.exists(scores_filename):\n",
        "            with open(scores_filename, 'r') as f:\n",
        "                scores = json.load(f)\n",
        "                scores_dict.setdefault(model_name, {}).update({model_type: scores})\n",
        "\n",
        "# 매트릭 이름 설정\n",
        "metric_columns = {\n",
        "    'Stroke': ['Model', 'ModelType', 'MSE', 'RMSE', 'MAE', 'R2'],\n",
        "    'Penalty': ['Model', 'ModelType', 'MSE', 'RMSE', 'MAE', 'R2'],\n",
        "    'Putt': ['Model', 'ModelType', 'MSE', 'RMSE', 'MAE', 'R2'],\n",
        "    'FW_Hit': ['Model', 'ModelType', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
        "}\n",
        "\n",
        "# 결과를 DataFrame으로 변환\n",
        "results_df = pd.concat(\n",
        "    [pd.DataFrame([(model, mt, *m.values()) for mt, m in data.items()], columns=metric_columns[model]) for model, data in results_dict.items()]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "params_df = pd.DataFrame([(model, mt, p) for model, data in params_dict.items() for mt, p in data.items()],\n",
        "                         columns=['Model', 'ModelType', 'Params'])\n",
        "\n",
        "scores_df = pd.DataFrame([(model, mt, *s.values()) for model, data in scores_dict.items() for mt, s in data.items()],\n",
        "                         columns=['Model', 'ModelType', 'TrainScore', 'ValidScore'])\n",
        "\n",
        "# 결과 출력 (소수점 3째자리로 강제 표시하여 출력)\n",
        "def format_float(val):\n",
        "    try:\n",
        "        return f\"{float(val):.3f}\"\n",
        "    except ValueError:\n",
        "        return val\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"  * {model_name}\")\n",
        "    print(f\"    - {model_name} 평가 결과:\")\n",
        "    if model_name in ['Stroke', 'Penalty', 'Putt']:\n",
        "        df = results_df[results_df['Model'] == model_name][['ModelType', 'MSE', 'RMSE', 'MAE', 'R2']].map(format_float)\n",
        "        display(df)\n",
        "    elif model_name == 'FW_Hit':\n",
        "        df = results_df[results_df['Model'] == model_name][['ModelType', 'Accuracy', 'Precision', 'Recall', 'F1']].map(format_float)\n",
        "        display(df)\n",
        "\n",
        "    print(f\"    - {model_name} 최적 파라미터:\")\n",
        "    display(params_df[params_df['Model'] == model_name])\n",
        "\n",
        "    print(f\"    - {model_name} 훈련 및 검증 데이터 점수:\")\n",
        "    df = scores_df[scores_df['Model'] == model_name].map(format_float)\n",
        "    display(df)\n",
        "\n",
        "# 평가 결과 저장\n",
        "results_df.to_parquet(output_file_path)\n",
        "\n",
        "# 최적 파라미터와 점수 저장\n",
        "params_output_file_name = 'gScore_Model_Params.parquet'\n",
        "params_output_file_path = os.path.join(base_path, sub_directory_name, params_output_file_name)\n",
        "params_df.to_parquet(params_output_file_path)\n",
        "\n",
        "scores_output_file_name = 'gScore_Model_Scores.parquet'\n",
        "scores_output_file_path = os.path.join(base_path, sub_directory_name, scores_output_file_name)\n",
        "scores_df.to_parquet(scores_output_file_path)\n",
        "\n",
        "print(f\"  - 모델 평가 결과를 '{output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "print(f\"  - 최적 파라미터를 '{params_output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "print(f\"  - 훈련 및 검증 데이터 점수를 '{scores_output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XJNWEupWjUoy",
      "metadata": {
        "id": "XJNWEupWjUoy"
      },
      "outputs": [],
      "source": [
        "# 03-2. 모델별 최적 파라미터 테이블 생성 및 저장 (240703)\n",
        "print(\"03-2. 모델별 최적 파라미터 테이블 생성 및 저장\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "sub_directory_name = 'Output'\n",
        "output_file_name = 'gScore_Model_Params_Tables.parquet'\n",
        "output_file_path = os.path.join(base_path, sub_directory_name, output_file_name)\n",
        "\n",
        "# 모델별 최적 파라미터 테이블 생성\n",
        "model_types = ['DecisionTree', 'RandomForest', 'SVM', 'XGBoost', 'LightGBM', 'CatBoost', 'KNN']\n",
        "model_names = ['Stroke', 'Penalty', 'Putt', 'FW_Hit']\n",
        "param_tables = {}\n",
        "\n",
        "for model_type in model_types:\n",
        "    param_dict = {}\n",
        "    for model_name in model_names:\n",
        "        # 최적 파라미터 로드\n",
        "        params_filename = f\"{model_file_path}/{model_type}_{model_name}_params.json\"\n",
        "        if os.path.exists(params_filename):\n",
        "            with open(params_filename, 'r') as f:\n",
        "                params = json.load(f)\n",
        "                param_dict[model_name] = params\n",
        "\n",
        "    # 최적 파라미터를 DataFrame으로 변환\n",
        "    if param_dict:\n",
        "        param_df = pd.DataFrame(param_dict).T\n",
        "        param_tables[model_type] = param_df\n",
        "\n",
        "# 결과 출력\n",
        "for model_type, param_df in param_tables.items():\n",
        "    print(f\"  * {model_type} 최적 파라미터:\")\n",
        "    display(param_df)\n",
        "\n",
        "# 최적 파라미터 테이블 저장\n",
        "param_tables_df = pd.concat(param_tables, keys=param_tables.keys()).reset_index(level=0).rename(columns={'level_0': 'ModelType'})\n",
        "param_tables_df.to_parquet(output_file_path)\n",
        "\n",
        "print(f\"  - 모델별 최적 파라미터 테이블을 '{output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EAIbFxPYMNPf",
      "metadata": {
        "id": "EAIbFxPYMNPf"
      },
      "outputs": [],
      "source": [
        "# 03-3. 모델 평가 결과 시각화 (240703)\n",
        "print(\"03-3. 모델 평가 결과 시각화\")\n",
        "\n",
        "# 시각화 함수 정의\n",
        "def plot_metrics(metric, title, ylabel, data, ax, is_max_best=True, show_legend=True):\n",
        "    sns.barplot(data=data, x='ModelType', y=metric, hue='Model', ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.set_xlabel('ModelType')\n",
        "    if show_legend:\n",
        "        ax.legend(title='Model', loc='upper right')\n",
        "    else:\n",
        "        ax.legend_.remove()\n",
        "    # 최고 또는 최저값에 가로선 추가\n",
        "    if is_max_best:\n",
        "        best_value = data[metric].max()\n",
        "    else:\n",
        "        best_value = data[metric].min()\n",
        "    ax.axhline(best_value, color='red', linestyle='--')\n",
        "\n",
        "# Stroke에 대한 그래프\n",
        "print(\"  * Stroke\")\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "stroke_data = results_df[results_df['Model'] == 'Stroke']\n",
        "plot_metrics('MSE', 'Stroke - Mean Squared Error (MSE)', 'MSE', stroke_data, axs[0, 0], is_max_best=False, show_legend=False)\n",
        "plot_metrics('RMSE', 'Stroke - Root Mean Squared Error (RMSE)', 'RMSE', stroke_data, axs[0, 1], is_max_best=False, show_legend=False)\n",
        "plot_metrics('MAE', 'Stroke - Mean Absolute Error (MAE)', 'MAE', stroke_data, axs[1, 0], is_max_best=False, show_legend=False)\n",
        "plot_metrics('R2', 'Stroke - R-Squared (R2)', 'R2', stroke_data, axs[1, 1], is_max_best=True, show_legend=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Penalty에 대한 그래프\n",
        "print(f\"\\n  * Penalty\")\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "penalty_data = results_df[results_df['Model'] == 'Penalty']\n",
        "plot_metrics('MSE', 'Penalty - Mean Squared Error (MSE)', 'MSE', penalty_data, axs[0, 0], is_max_best=False, show_legend=False)\n",
        "plot_metrics('RMSE', 'Penalty - Root Mean Squared Error (RMSE)', 'RMSE', penalty_data, axs[0, 1], is_max_best=False, show_legend=False)\n",
        "plot_metrics('MAE', 'Penalty - Mean Absolute Error (MAE)', 'MAE', penalty_data, axs[1, 0], is_max_best=False, show_legend=False)\n",
        "plot_metrics('R2', 'Penalty - R-Squared (R2)', 'R2', penalty_data, axs[1, 1], is_max_best=True, show_legend=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Putt에 대한 그래프\n",
        "print(f\"\\n  * Putt\")\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "putt_data = results_df[results_df['Model'] == 'Putt']\n",
        "plot_metrics('MSE', 'Putt - Mean Squared Error (MSE)', 'MSE', putt_data, axs[0, 0], is_max_best=False, show_legend=False)\n",
        "plot_metrics('RMSE', 'Putt - Root Mean Squared Error (RMSE)', 'RMSE', putt_data, axs[0, 1], is_max_best=False, show_legend=False)\n",
        "plot_metrics('MAE', 'Putt - Mean Absolute Error (MAE)', 'MAE', putt_data, axs[1, 0], is_max_best=False, show_legend=False)\n",
        "plot_metrics('R2', 'Putt - R-Squared (R2)', 'R2', putt_data, axs[1, 1], is_max_best=True, show_legend=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# FW Hit에 대한 그래프\n",
        "print(f\"\\n  * FW Hit\")\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "fw_hit_data = results_df[results_df['Model'] == 'FW_Hit']\n",
        "plot_metrics('Accuracy', 'FW Hit - Accuracy', 'Accuracy', fw_hit_data, axs[0, 0], is_max_best=True, show_legend=False)\n",
        "plot_metrics('Precision', 'FW Hit - Precision', 'Precision', fw_hit_data, axs[0, 1], is_max_best=True, show_legend=False)\n",
        "plot_metrics('Recall', 'FW Hit - Recall', 'Recall', fw_hit_data, axs[1, 0], is_max_best=True, show_legend=False)\n",
        "plot_metrics('F1', 'FW Hit - F1 Score', 'F1 Score', fw_hit_data, axs[1, 1], is_max_best=True, show_legend=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hJWtHHzI4uMg",
      "metadata": {
        "id": "hJWtHHzI4uMg"
      },
      "outputs": [],
      "source": [
        "# 03-4. 종합 평가 결과 및 모델 추천 (240707)\n",
        "print(\"03-4. 종합 평가 결과 및 모델 추천\")\n",
        "\n",
        "# 평가 결과 불러오기\n",
        "sub_directory_name = 'Output'\n",
        "results_file_path = os.path.join(base_path, sub_directory_name, 'gScore_Model_Evaluation_Results.parquet')\n",
        "scores_file_path = os.path.join(base_path, sub_directory_name, 'gScore_Model_Scores.parquet')\n",
        "\n",
        "# 평가 결과 로드\n",
        "results_df = pd.read_parquet(results_file_path)\n",
        "scores_df = pd.read_parquet(scores_file_path)\n",
        "\n",
        "# 가중치 설정\n",
        "weights_classification = {'Accuracy': 0.4, 'Precision': 0.2, 'Recall': 0.2, 'F1': 0.2}\n",
        "weights_regression = {'R2': 0.4, 'MSE': 0.3, 'MAE': 0.15, 'RMSE': 0.15}\n",
        "\n",
        "# 역수 변환 함수\n",
        "def inverse_weight(value, weight):\n",
        "    return (1 - value) * weight\n",
        "\n",
        "# 종합 점수 계산 함수\n",
        "def calculate_composite_score(model_results, weights, inverse_metrics):\n",
        "    scores = {}\n",
        "    for model_name, metrics in model_results.items():\n",
        "        composite_score = sum(\n",
        "            inverse_weight(metrics.get(metric, 0), weight) if metric in inverse_metrics else metrics.get(metric, 0) * weight\n",
        "            for metric, weight in weights.items()\n",
        "        )\n",
        "        scores[model_name] = composite_score\n",
        "    return scores\n",
        "\n",
        "# 모델 추천 함수\n",
        "def recommend_models(results_df, model_names, weights_classification, weights_regression):\n",
        "    recommendations = {}\n",
        "    inverse_metrics_regression = ['MSE', 'MAE', 'RMSE']\n",
        "    inverse_metrics_classification = []\n",
        "\n",
        "    for model_name in model_names:\n",
        "        if model_name == 'FW_Hit':\n",
        "            scores = calculate_composite_score(\n",
        "                results_df[results_df['Model'] == model_name].set_index('ModelType').to_dict('index'),\n",
        "                weights_classification, inverse_metrics_classification\n",
        "            )\n",
        "        else:\n",
        "            scores = calculate_composite_score(\n",
        "                results_df[results_df['Model'] == model_name].set_index('ModelType').to_dict('index'),\n",
        "                weights_regression, inverse_metrics_regression\n",
        "            )\n",
        "\n",
        "        sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        recommendations[model_name] = [(model, score) for model, score in sorted_scores]\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# 과적합/과소적합 경고 추가\n",
        "def add_overfitting_warning(results_df, scores_df, model_names):\n",
        "    warnings = {model_name: [] for model_name in model_names}\n",
        "    for model_name in model_names:\n",
        "        for model_type in results_df[results_df['Model'] == model_name]['ModelType'].unique():\n",
        "            train_score = round(scores_df[(scores_df['Model'] == model_name) & (scores_df['ModelType'] == model_type)]['TrainScore'].values[0], 3)\n",
        "            valid_score = round(scores_df[(scores_df['Model'] == model_name) & (scores_df['ModelType'] == model_type)]['ValidScore'].values[0], 3)\n",
        "            if train_score == 1.0 and valid_score == 1.0:\n",
        "                warnings[model_name].append(f\"{model_type} 모델: 과적합 의심 (훈련 및 검증 데이터 점수 모두 1.0)\")\n",
        "            elif train_score < 0.7 and valid_score < 0.7:\n",
        "                warnings[model_name].append(f\"{model_type} 모델: 과소적합 의심 (훈련 및 검증 데이터 점수 모두 0.7 미만)\")\n",
        "            elif train_score - valid_score > 0.1:\n",
        "                warnings[model_name].append(f\"{model_type} 모델: 과적합 의심 (검증 데이터 점수가 {(train_score - valid_score)*100:.1f}%p 낮음)\")\n",
        "            elif valid_score - train_score > 0.1:\n",
        "                warnings[model_name].append(f\"{model_type} 모델: 과소적합 의심 (검증 데이터 점수가 {(valid_score - train_score)*100:.1f}%p 높음)\")\n",
        "    return warnings\n",
        "\n",
        "# 모델 추천\n",
        "model_names = ['Stroke', 'Penalty', 'Putt', 'FW_Hit']\n",
        "recommendations = recommend_models(results_df, model_names, weights_classification, weights_regression)\n",
        "\n",
        "# 과적합/과소적합 경고\n",
        "warnings = add_overfitting_warning(results_df, scores_df, model_names)\n",
        "\n",
        "# 결과 출력 함수\n",
        "def display_recommendations_table(recommendations, results_df, scores_df, warnings):\n",
        "    recommendations_data = []\n",
        "    for target, models in recommendations.items():\n",
        "        for i, (model, score) in enumerate(models, 1):\n",
        "            model_metrics = results_df[(results_df['Model'] == target) & (results_df['ModelType'] == model)].iloc[0].to_dict()\n",
        "            train_score = round(scores_df[(scores_df['Model'] == target) & (scores_df['ModelType'] == model)]['TrainScore'].values[0], 3)\n",
        "            valid_score = round(scores_df[(scores_df['Model'] == target) & (scores_df['ModelType'] == model)]['ValidScore'].values[0], 3)\n",
        "            score_diff = round(abs(train_score - valid_score), 3)\n",
        "            metrics_info = {key: round(value, 3) for key, value in model_metrics.items() if key not in ['Model', 'ModelType'] and pd.notna(value)}\n",
        "            recommendations_data.append([target, model, round(score, 3)] + list(metrics_info.values()) + [train_score, valid_score, score_diff])\n",
        "\n",
        "    metric_columns = {\n",
        "        'Stroke': ['Target', 'Model', 'Score', 'MSE', 'RMSE', 'MAE', 'R2', 'TrainScore', 'ValidScore', 'ScoreDiff'],\n",
        "        'Penalty': ['Target', 'Model', 'Score', 'MSE', 'RMSE', 'MAE', 'R2', 'TrainScore', 'ValidScore', 'ScoreDiff'],\n",
        "        'Putt': ['Target', 'Model', 'Score', 'MSE', 'RMSE', 'MAE', 'R2', 'TrainScore', 'ValidScore', 'ScoreDiff'],\n",
        "        'FW_Hit': ['Target', 'Model', 'Score', 'Accuracy', 'Precision', 'Recall', 'F1', 'TrainScore', 'ValidScore', 'ScoreDiff']\n",
        "    }\n",
        "\n",
        "    recommendations_df_list = []\n",
        "    for target in model_names:\n",
        "        target_df = pd.DataFrame([data for data in recommendations_data if data[0] == target], columns=metric_columns[target])\n",
        "        recommendations_df_list.append(target_df)\n",
        "\n",
        "    return recommendations_df_list\n",
        "\n",
        "recommendations_df_list = display_recommendations_table(recommendations, results_df, scores_df, warnings)\n",
        "\n",
        "# 테이블 및 경고 출력\n",
        "for target_df in recommendations_df_list:\n",
        "    target_name = target_df['Target'].iloc[0]\n",
        "    print(f\"\\n  * {target_name}\")\n",
        "    for warning in warnings[target_name]:\n",
        "        print(f\"    - {warning}\")\n",
        "    display(target_df)\n",
        "\n",
        "# 결과 저장\n",
        "recommendations_output_file_path = os.path.join(base_path, sub_directory_name, 'Model_Recommendations.json')\n",
        "with open(recommendations_output_file_path, 'w') as f:\n",
        "    json.dump(recommendations, f, indent=4)\n",
        "print(f\"  - 모델 추천 결과를 '{recommendations_output_file_path}'에 저장하였습니다.\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbuJbsUh2Dml",
      "metadata": {
        "id": "bbuJbsUh2Dml"
      },
      "source": [
        "## 03-5. 모델 평가 결과"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oymp2Js4El8e",
      "metadata": {
        "id": "oymp2Js4El8e"
      },
      "source": [
        "### 개요\n",
        "다양한 머신러닝 모델을 사용하여 `Stroke`, `Penalty`, `Putt`, `FW_Hit` 네 가지 타겟 변수를 예측하는 성능을 평가하였으며, 평가에는 `MSE`, `RMSE`, `MAE`, `R2`, `Accuracy`, `Precision`, `Recall`, `F1 Score`와 같은 다양한 지표를 사용하였습니다. 각 타겟 변수에 대해 **최적의 성능을 보인 3가지 모델**을 선정하여 제시합니다.\n",
        "\n",
        "### 평가 지표 설명\n",
        "\n",
        "#### 회귀 모델 (Regression Models)\n",
        "\n",
        "- **MSE (Mean Squared Error, 평균제곱오차)**: 예측 값과 실제 값의 차이를 제곱하여 평균한 값. 값이 *작을수록* 예측 정확도가 높음을 의미.\n",
        "- **RMSE (Root Mean Squared Error, 평균제곱근오차)**: MSE의 제곱근으로, 예측 값과 실제 값의 차이를 직관적으로 이해하기 쉽게 변환한 값. 값이 *작을수록* 예측 정확도가 높음을 의미.\n",
        "- **MAE (Mean Absolute Error, 평균절대오차)**: 예측 값과 실제 값의 차이를 절대값으로 변환하여 평균한 값. 값이 *작을수록* 예측 정확도가 높음을 의미.\n",
        "- **R2 (R-Squared, 결정계수)**: 모델이 실제 값을 얼마나 잘 설명하는지를 나타내는 지표. *1에 가까울수록* 모델의 설명력이 높음을 의미.\n",
        "\n",
        "#### 분류 모델 (Classification Models)\n",
        "\n",
        "- **Accuracy (정확도)**: 전체 예측에서 맞춘 비율을 나타냄. 값이 *클수록* 정확도가 높음을 의미.\n",
        "- **Precision (정밀도)**: 모델이 양성으로 예측한 것 중 실제 양성의 비율. 값이 *클수록* 정밀도가 높음을 의미.\n",
        "- **Recall (재현율)**: 실제 양성 중 모델이 양성으로 맞춘 비율. 값이 *클수록* 재현율이 높음을 의미.\n",
        "- **F1 Score**: Precision과 Recall의 조화 평균으로, 두 지표의 *균형*을 나타냄. 값이 *클수록* 성능이 균형 잡혔음을 의미.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Stroke\n",
        "\n",
        "#### 모델 평가 결과\n",
        "| Model          | MSE   | RMSE  | MAE   | R2    |\n",
        "|----------------|-------|-------|-------|-------|\n",
        "| DecisionTree   | 0.494 | 0.703 | 0.536 | 0.607 |\n",
        "| RandomForest   | 0.435 | 0.660 | 0.503 | 0.654 |\n",
        "| SVM            | 0.514 | 0.717 | 0.565 | 0.591 |\n",
        "| XGBoost        | 0.486 | 0.697 | 0.543 | 0.613 |\n",
        "| LightGBM       | 0.472 | 0.687 | 0.530 | 0.625 |\n",
        "| CatBoost       | 0.435 | 0.659 | 0.517 | 0.654 |\n",
        "| KNN            | 0.530 | 0.728 | 0.572 | 0.578 |\n",
        "\n",
        "#### 훈련 및 검증 데이터 점수\n",
        "| Model          | TrainScore | ValidScore |\n",
        "|----------------|------------|------------|\n",
        "| DecisionTree   | 0.619      | 0.552      |\n",
        "| RandomForest   | 0.662      | 0.614      |\n",
        "| SVM            | 0.608      | 0.512      |\n",
        "| XGBoost        | 0.624      | 0.564      |\n",
        "| LightGBM       | 0.635      | 0.577      |\n",
        "| CatBoost       | 0.665      | 0.605      |\n",
        "| KNN            | 0.584      | 0.554      |\n",
        "\n",
        "#### 분석 및 해석\n",
        "- **RandomForest**가 MSE, RMSE, MAE에서 낮은 값을 보였으며, R2 점수도 0.654로 높은 설명력을 보였습니다.\n",
        "- **CatBoost** 역시 우수한 성능을 보였으며, 특히 R2가 0.654로 높았습니다.\n",
        "- **LightGBM**은 전반적으로 안정적인 성능을 보였습니다.\n",
        "\n",
        "#### 추천 모델\n",
        "1. **RandomForest**: 높은 성능과 설명력을 보임.\n",
        "2. **CatBoost**: 우수한 예측 성능과 안정성.\n",
        "3. **LightGBM**: 전반적인 성능이 뛰어남.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Penalty\n",
        "\n",
        "#### 모델 평가 결과\n",
        "| Model          | MSE   | RMSE  | MAE   | R2    |\n",
        "|----------------|-------|-------|-------|-------|\n",
        "| DecisionTree   | 0.226 | 0.475 | 0.348 | 0.648 |\n",
        "| RandomForest   | 0.208 | 0.456 | 0.332 | 0.676 |\n",
        "| SVM            | 0.283 | 0.532 | 0.412 | 0.559 |\n",
        "| XGBoost        | 0.215 | 0.464 | 0.340 | 0.665 |\n",
        "| LightGBM       | 0.204 | 0.452 | 0.327 | 0.683 |\n",
        "| CatBoost       | 0.225 | 0.474 | 0.346 | 0.650 |\n",
        "| KNN            | 0.273 | 0.522 | 0.379 | 0.575 |\n",
        "\n",
        "#### 훈련 및 검증 데이터 점수\n",
        "| Model          | TrainScore | ValidScore |\n",
        "|----------------|------------|------------|\n",
        "| DecisionTree   | 0.645      | 0.662      |\n",
        "| RandomForest   | 0.666      | 0.714      |\n",
        "| SVM            | 0.551      | 0.589      |\n",
        "| XGBoost        | 0.657      | 0.696      |\n",
        "| LightGBM       | 0.673      | 0.720      |\n",
        "| CatBoost       | 0.644      | 0.674      |\n",
        "| KNN            | 0.565      | 0.615      |\n",
        "\n",
        "#### 분석 및 해석\n",
        "- **LightGBM**가 R2가 0.683로 가장 높았으며, MSE, RMSE, MAE 모두 낮아 최상의 성능을 보였습니다.\n",
        "- **RandomForest** 역시 우수한 성능을 보였습니다.\n",
        "- **XGBoost**는 전반적으로 안정적인 성능을 보였습니다.\n",
        "\n",
        "#### 추천 모델\n",
        "1. **LightGBM**: 높은 성능과 설명력을 보임.\n",
        "2. **RandomForest**: 우수한 예측 성능과 안정성.\n",
        "3. **XGBoost**: 전반적인 성능이 뛰어남.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Putt\n",
        "\n",
        "#### 모델 평가 결과\n",
        "| Model          | MSE   | RMSE  | MAE   | R2    |\n",
        "|----------------|-------|-------|-------|-------|\n",
        "| DecisionTree   | 0.000 | 0.000 | 0.000 | 1.000 |\n",
        "| RandomForest   | 0.000 | 0.000 | 0.000 | 1.000 |\n",
        "| SVM            | 0.005 | 0.072 | 0.045 | 0.990 |\n",
        "| XGBoost        | 0.000 | 0.000 | 0.000 | 1.000 |\n",
        "| LightGBM       | 0.001 | 0.033 | 0.014 | 0.998 |\n",
        "| CatBoost       | 0.000 | 0.000 | 0.000 | 1.000 |\n",
        "| KNN            | 0.144 | 0.380 | 0.251 | 0.720 |\n",
        "\n",
        "#### 훈련 및 검증 데이터 점수\n",
        "| Model          | TrainScore | ValidScore |\n",
        "|----------------|------------|------------|\n",
        "| DecisionTree   | 1.000      | 1.000      |\n",
        "| RandomForest   | 1.000      | 1.000      |\n",
        "| SVM            | 0.990      | 0.990      |\n",
        "| XGBoost        | 1.000      | 1.000      |\n",
        "| LightGBM       | 0.998      | 0.998      |\n",
        "| CatBoost       | 1.000      | 1.000      |\n",
        "| KNN            | 0.722      | 0.711      |\n",
        "\n",
        "#### 분석 및 해석\n",
        "- **DecisionTree**, **RandomForest**, **XGBoost**, **CatBoost**가 모든 지표에서 완벽한 성능을 보였습니다.\n",
        "- **LightGBM**은 약간의 오차가 있으나 여전히 우수한 성능을 보였습니다.\n",
        "\n",
        "#### 추천 모델\n",
        "1. **DecisionTree**: 모든 지표에서 완벽한 성능을 보임.\n",
        "2. **RandomForest**: 우수한 예측 성능과 안정성.\n",
        "3. **XGBoost**: 전반적인 성능이 뛰어남.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. FW_Hit\n",
        "\n",
        "#### 모델 평가 결과\n",
        "| Model          | Accuracy | Precision | Recall | F1    |\n",
        "|----------------|----------|-----------|--------|-------|\n",
        "| DecisionTree   | 0.702    | 0.703     | 0.702  | 0.703 |\n",
        "| RandomForest   | 0.917    | 0.917     | 0.917  | 0.917 |\n",
        "| SVM            | 0.679    | 0.665     | 0.679  | 0.666 |\n",
        "| XGBoost        | 0.786    | 0.783     | 0.786  | 0.783 |\n",
        "| LightGBM       | 0.756    | 0.751     | 0.756  | 0.752 |\n",
        "| CatBoost       | 0.883    | 0.883     | 0.883  | 0.883 |\n",
        "| KNN            | 0.754    | 0.765     | 0.754  | 0.729 |\n",
        "\n",
        "#### 훈련 및 검증 데이터 점수\n",
        "| Model          | TrainScore | ValidScore |\n",
        "|----------------|------------|------------|\n",
        "| DecisionTree   | 0.705      | 0.691      |\n",
        "| RandomForest   | 0.923      | 0.895      |\n",
        "| SVM            | 0.691      | 0.630      |\n",
        "| XGBoost        | 0.798      | 0.741      |\n",
        "| LightGBM       | 0.767      | 0.710      |\n",
        "| CatBoost       | 0.890      | 0.852      |\n",
        "| KNN            | 0.769      | 0.698      |\n",
        "\n",
        "#### 분석 및 해석\n",
        "- **RandomForest**가 Accuracy, Precision, Recall, F1 Score에서 높은 값을 보였으며, 전반적으로 우수한 성능을 보였습니다.\n",
        "- **CatBoost**와 **XGBoost**도 높은 성능을 보였습니다.\n",
        "- **KNN**은 훈련 및 검증 데이터에서 비교적 낮은 성능을 보였습니다.\n",
        "\n",
        "#### 추천 모델\n",
        "1. **RandomForest**: 전반적인 성능이 뛰어남.\n",
        "2. **CatBoost**: 높은 성능과 설명력을 보임.\n",
        "3. **XGBoost**: 우수한 예측 성능과 안정성.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. 모델별 최적 파라미터\n",
        "\n",
        "#### DecisionTree (의사결정트리)\n",
        "| Model        | max_depth | min_samples_leaf | min_samples_split |\n",
        "|--------------|-----------|------------------|-------------------|\n",
        "| Stroke       | 4         | 2                | 2                 |\n",
        "| Penalty      | 4         | 3                | 2                 |\n",
        "| Putt         | 3         | 2                | 2                 |\n",
        "| FW_Hit       | 3         | 2                | 2                 |\n",
        "\n",
        "#### RandomForest (랜덤 포레스트)\n",
        "| Model        | max_depth | min_samples_leaf | min_samples_split |\n",
        "|--------------|-----------|------------------|-------------------|\n",
        "| Stroke       | 5         | 4                | 2                 |\n",
        "| Penalty      | 5         | 3                | 2                 |\n",
        "| Putt         | 5         | 2                | 2                 |\n",
        "| FW_Hit       | 10        | 2                | 2                 |\n",
        "\n",
        "#### SVM (서포트 벡터 머신)\n",
        "| Model        | C   | epsilon | kernel  |\n",
        "|--------------|-----|---------|---------|\n",
        "| Stroke       | 0.1 | 0.2     | linear  |\n",
        "| Penalty      | 1   | 0.5     | linear  |\n",
        "| Putt         | 0.1 | 0.2     | linear  |\n",
        "| FW_Hit       | 1   | -       | linear  |\n",
        "\n",
        "#### XGBoost\n",
        "| Model        | colsample_bytree | gamma | learning_rate | max_depth | min_child_weight |\n",
        "|--------------|------------------|-------|---------------|-----------|------------------|\n",
        "| Stroke       | 1.0              | 0.5   | 0.1           | 2         | 1                |\n",
        "| Penalty      | 0.5              | 0.1   | 0.05          | 2         | 1                |\n",
        "| Putt         | 1.0              | 1e-09 | 0.1           | 4         | 20               |\n",
        "| FW_Hit       | 0.5              | 0.1   | 0.05          | 3         | 1                |\n",
        "\n",
        "#### LightGBM\n",
        "| Model        | learning_rate | max_depth | min_child_samples | n_estimators |\n",
        "|--------------|---------------|-----------|-------------------|--------------|\n",
        "| Stroke       | 0.1           | 2         | 20                | 100          |\n",
        "| Penalty      | 0.05          | 2         | 20                | 100          |\n",
        "| Putt         | 0.1           | 4         | 20                | 500          |\n",
        "| FW_Hit       | 0.1           | 2         | 20                | 100          |\n",
        "\n",
        "#### CatBoost\n",
        "| Model        | depth | iterations | l2_leaf_reg | learning_rate |\n",
        "|--------------|-------|------------|-------------|---------------|\n",
        "| Stroke       | 5     | 100        | 1           | 0.1           |\n",
        "| Penalty      | 2     | 1000       | 1           | 0.01          |\n",
        "| Putt         | 2     | 500        | 3           | 0.1           |\n",
        "| FW_Hit       | 5     | 500        | 1           | 0.1           |\n",
        "\n",
        "#### KNN (K-최근접 이웃)\n",
        "| Model        | n_neighbors | p   | weights   |\n",
        "|--------------|-------------|-----|-----------|\n",
        "| Stroke       | 6           | 2   | uniform   |\n",
        "| Penalty      | 7           | 2   | uniform   |\n",
        "| Putt         | 3           | 1   | uniform   |\n",
        "| FW_Hit       | 6           | 1   | uniform   |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PTBqcZbvyuoG",
      "metadata": {
        "id": "PTBqcZbvyuoG"
      },
      "source": [
        "# 04. 최종 예측 (최종 파일: 5_final_predictions.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RunryD6eG9vd",
      "metadata": {
        "id": "RunryD6eG9vd"
      },
      "outputs": [],
      "source": [
        "# 04-1. stroke 예측 및 정수 저장 (240630)\n",
        "print(\"04-1. stroke 예측 및 정수 저장\")\n",
        "\n",
        "# 데이터 복사\n",
        "predict_df_copy = predict_df.copy()\n",
        "\n",
        "# 모델 불러오기\n",
        "#model_stroke, features_stroke = load_model('CatBoost', 'Stroke')\n",
        "model_stroke, features_stroke = load_model('RandomForest', 'Stroke')\n",
        "model_penalty, features_penalty = load_model('LightGBM', 'Penalty')\n",
        "#model_penalty, features_penalty = load_model('RandomForest', 'Penalty')\n",
        "#model_penalty, features_penalty = load_model('XGBoost', 'Penalty')\n",
        "model_putt, features_putt = load_model('DecisionTree', 'Putt')\n",
        "model_fw_hit, features_fw_hit = load_model('RandomForest', 'FW_Hit')\n",
        "#model_fw_hit, features_fw_hit = load_model('CatBoost', 'FW_Hit')\n",
        "\n",
        "# 파일 경로 설정\n",
        "sub_directory_name = 'Output'\n",
        "output_file_name = '1_stroke_predictions.csv'\n",
        "output_file_path = os.path.join(base_path, sub_directory_name, output_file_name)\n",
        "\n",
        "# stroke 예측을 위한 데이터 준비\n",
        "X_predict_stroke = predict_df_copy[features_stroke].dropna()\n",
        "predicted_stroke = model_stroke.predict(X_predict_stroke)\n",
        "predict_df_copy.loc[X_predict_stroke.index, 'stroke'] = np.round(predicted_stroke).astype(int)  # 예측값 정수화\n",
        "\n",
        "print(f\"  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터 저장\n",
        "predict_df_copy.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"  - 데이터프레임을 '{output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jsg8RQvmJEr2",
      "metadata": {
        "id": "jsg8RQvmJEr2"
      },
      "outputs": [],
      "source": [
        "# 04-2. penalty 예측 및 정수 저장 (240630)\n",
        "print(\"04-2. penalty 예측 및 정수 저장\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "output_file_name = '2_penalty_predictions.csv'\n",
        "output_file_path = os.path.join(base_path, sub_directory_name, output_file_name)\n",
        "\n",
        "# score_minus_stroke 변수 업데이트\n",
        "predict_df_copy['score_minus_stroke'] = predict_df_copy['score'] - predict_df_copy['stroke']\n",
        "\n",
        "# penalty 예측을 위한 데이터 준비\n",
        "X_predict_penalty = predict_df_copy[features_penalty].dropna()\n",
        "predicted_penalty = model_penalty.predict(X_predict_penalty)\n",
        "predict_df_copy.loc[X_predict_penalty.index, 'penalty'] = np.round(predicted_penalty).astype(int)  # 예측값 정수화\n",
        "\n",
        "print(f\"  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터 저장\n",
        "predict_df_copy.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"  - 데이터프레임을 '{output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ISFw_ce9Jsba",
      "metadata": {
        "id": "ISFw_ce9Jsba"
      },
      "outputs": [],
      "source": [
        "# 04-3. putt 예측 및 정수 저장 (240630)\n",
        "print(\"04-3. putt 예측 및 정수 저장\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "output_file_name = '3_putt_predictions.csv'\n",
        "output_file_path = os.path.join(base_path, sub_directory_name, output_file_name)\n",
        "\n",
        "# score_minus_stroke_minus_penalty 변수 업데이트\n",
        "predict_df_copy['score_minus_stroke_minus_penalty'] = predict_df_copy['score_minus_stroke'] - predict_df_copy['penalty']\n",
        "\n",
        "# putt 예측을 위한 데이터 준비\n",
        "X_predict_putt = predict_df_copy[features_putt].dropna()\n",
        "predicted_putt = model_putt.predict(X_predict_putt)\n",
        "predict_df_copy.loc[X_predict_putt.index, 'putt'] = np.round(predicted_putt).astype(int)  # 예측값 정수화\n",
        "\n",
        "print(f\"  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터 저장\n",
        "predict_df_copy.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"  - 데이터프레임을 '{output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YSpxSTUiKmDL",
      "metadata": {
        "id": "YSpxSTUiKmDL"
      },
      "outputs": [],
      "source": [
        "# 04-4. stroke + penalty + putt vs. score 비교 (240630)\n",
        "print(\"04-4. stroke + penalty + putt vs. score 비교\")\n",
        "\n",
        "# stroke + penalty + putt 합계 계산\n",
        "predict_df_copy['stroke_penalty_putt_sum'] = predict_df_copy['stroke'] + predict_df_copy['penalty'] + predict_df_copy['putt']\n",
        "\n",
        "# score와의 차이 계산\n",
        "predict_df_copy['score_difference'] = predict_df_copy['score'] - predict_df_copy['stroke_penalty_putt_sum']\n",
        "\n",
        "# score_difference가 0인 경우 NaN으로 변환\n",
        "predict_df_copy['score_difference'] = predict_df_copy['score_difference'].replace(0, np.nan)\n",
        "\n",
        "# 결과 출력\n",
        "display(predict_df_copy[['date_time', 'no', 'par', 'stroke', 'penalty', 'putt', 'stroke_penalty_putt_sum', 'score', 'score_difference']].head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "quObhPhfWeRj",
      "metadata": {
        "id": "quObhPhfWeRj"
      },
      "outputs": [],
      "source": [
        "# 04-5. score_difference 조정 및 업데이트 (240630)\n",
        "print(\"04-5. score_difference 조정 및 업데이트\")\n",
        "\n",
        "while predict_df_copy['score_difference'].notna().any():\n",
        "    for index, row in predict_df_copy.iterrows():\n",
        "        if not pd.isna(row['score_difference']):\n",
        "            # penalty에 score_difference 추가\n",
        "            new_penalty = row['penalty'] + row['score_difference']\n",
        "\n",
        "            if new_penalty < 0:\n",
        "                # penalty가 음수가 되면 putt에 그 값을 더하고 penalty는 0으로 설정\n",
        "                predict_df_copy.at[index, 'penalty'] = 0\n",
        "                predict_df_copy.at[index, 'putt'] += new_penalty\n",
        "            else:\n",
        "                # penalty 업데이트\n",
        "                predict_df_copy.at[index, 'penalty'] = new_penalty\n",
        "\n",
        "    # stroke, penalty, putt 합계 및 score_difference 재계산\n",
        "    predict_df_copy['stroke_penalty_putt_sum'] = predict_df_copy['stroke'] + predict_df_copy['penalty'] + predict_df_copy['putt']\n",
        "    predict_df_copy['score_difference'] = predict_df_copy['score'] - predict_df_copy['stroke_penalty_putt_sum']\n",
        "    predict_df_copy['score_difference'] = predict_df_copy['score_difference'].replace(0, np.nan)\n",
        "\n",
        "# 결과 출력\n",
        "display(predict_df_copy[['date_time', 'no', 'par', 'stroke', 'penalty', 'putt', 'stroke_penalty_putt_sum', 'score', 'score_difference']].head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "print(f\"\\n  - score_difference 조정을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yF2OfwiFyxu_",
      "metadata": {
        "id": "yF2OfwiFyxu_"
      },
      "outputs": [],
      "source": [
        "# 04-6. fw_hit 예측 및 정수 저장 (240630)\n",
        "print(\"04-6. fw_hit 예측 및 정수 저장\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "output_file_name = '4_fw_hit_predictions.csv'\n",
        "output_file_path = os.path.join(base_path, sub_directory_name, output_file_name)\n",
        "\n",
        "# fw_hit 예측을 위한 데이터 준비\n",
        "X_predict_fw_hit = predict_df_copy[predict_df_copy['par'] != 3][features_fw_hit].dropna()\n",
        "predicted_fw_hit = model_fw_hit.predict(X_predict_fw_hit)\n",
        "predict_df_copy.loc[X_predict_fw_hit.index, 'fw_hit'] = np.round(predicted_fw_hit).astype(int)  # 예측값 정수화\n",
        "\n",
        "print(f\"  - 예측을 완료하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터 저장\n",
        "predict_df_copy.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"  - 데이터프레임을 '{output_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Prediction DataFrame (predict_df_copy):\")\n",
        "display(predict_df_copy.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Prediction DataFrame Information (predict_df_copy):\")\n",
        "display_info_in_sections(predict_df_copy)\n",
        "\n",
        "# =================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6WdPaute8-cb",
      "metadata": {
        "id": "6WdPaute8-cb"
      },
      "outputs": [],
      "source": [
        "# 04-7. 예측된 내용을 최종 파일로 저장 (240810)\n",
        "print(\"04-7. 예측된 내용을 최종 파일로 저장\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "output_csv_file_name = '5_final_predictions.csv'\n",
        "output_parquet_file_name = '5_final_predictions.parquet'\n",
        "output_csv_file_path = os.path.join(base_path, sub_directory_name, output_csv_file_name)\n",
        "output_parquet_file_path = os.path.join(base_path, sub_directory_name, output_parquet_file_name)\n",
        "\n",
        "# 불필요한 열 제거\n",
        "columns_to_drop = [\n",
        "    'is_true', 'month', 'hour', 'season', 'course_type_b9',\n",
        "    'score_minus_stroke', 'score_minus_stroke_minus_penalty',\n",
        "    'stroke_penalty_putt_sum', 'score_difference'\n",
        "]\n",
        "predict_df_copy.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# predict_df_copy 복사하여 predict_temp_df 생성\n",
        "predict_temp_df = predict_df_copy.copy()\n",
        "\n",
        "# hole_no_temp 열 추가\n",
        "predict_temp_df['hole_no_temp'] = predict_temp_df.groupby('no').cumcount() + 1\n",
        "\n",
        "print(\"\\n  * Final Prediction DataFrame (predict_temp_df):\")\n",
        "display(predict_temp_df)\n",
        "\n",
        "# 최종 데이터프레임 초기화\n",
        "final_columns = [\n",
        "    'no', 'date_time', 'golf_course',\n",
        "    'stroke_f9_1', 'stroke_f9_2', 'stroke_f9_3', 'stroke_f9_4', 'stroke_f9_5', 'stroke_f9_6', 'stroke_f9_7', 'stroke_f9_8', 'stroke_f9_9',\n",
        "    'stroke_b9_1', 'stroke_b9_2', 'stroke_b9_3', 'stroke_b9_4', 'stroke_b9_5', 'stroke_b9_6', 'stroke_b9_7', 'stroke_b9_8', 'stroke_b9_9',\n",
        "    'putt_f9_1', 'putt_f9_2', 'putt_f9_3', 'putt_f9_4', 'putt_f9_5', 'putt_f9_6', 'putt_f9_7', 'putt_f9_8', 'putt_f9_9',\n",
        "    'putt_b9_1', 'putt_b9_2', 'putt_b9_3', 'putt_b9_4', 'putt_b9_5', 'putt_b9_6', 'putt_b9_7', 'putt_b9_8', 'putt_b9_9',\n",
        "    'penalty_f9_1', 'penalty_f9_2', 'penalty_f9_3', 'penalty_f9_4', 'penalty_f9_5', 'penalty_f9_6', 'penalty_f9_7', 'penalty_f9_8', 'penalty_f9_9',\n",
        "    'penalty_b9_1', 'penalty_b9_2', 'penalty_b9_3', 'penalty_b9_4', 'penalty_b9_5', 'penalty_b9_6', 'penalty_b9_7', 'penalty_b9_8', 'penalty_b9_9',\n",
        "    'fw_hit_f9_1', 'fw_hit_f9_2', 'fw_hit_f9_3', 'fw_hit_f9_4', 'fw_hit_f9_5', 'fw_hit_f9_6', 'fw_hit_f9_7', 'fw_hit_f9_8', 'fw_hit_f9_9',\n",
        "    'fw_hit_b9_1', 'fw_hit_b9_2', 'fw_hit_b9_3', 'fw_hit_b9_4', 'fw_hit_b9_5', 'fw_hit_b9_6', 'fw_hit_b9_7', 'fw_hit_b9_8', 'fw_hit_b9_9'\n",
        "]\n",
        "\n",
        "final_df_list = []\n",
        "\n",
        "for no in predict_temp_df['no'].unique():\n",
        "    row = {'no': no}\n",
        "    filtered_df = predict_temp_df[predict_temp_df['no'] == no]\n",
        "\n",
        "    # 첫번째 행의 date_time과 golf_course 정보 저장\n",
        "    row['date_time'] = filtered_df.iloc[0]['date_time']\n",
        "    row['golf_course'] = filtered_df.iloc[0]['golf_course']\n",
        "\n",
        "    for index, hole in filtered_df.iterrows():\n",
        "        hole_no_temp = hole['hole_no_temp']\n",
        "        if hole_no_temp <= 9:\n",
        "            hole_prefix = 'f9'\n",
        "            hole_no_str = hole_no_temp\n",
        "        else:\n",
        "            hole_prefix = 'b9'\n",
        "            hole_no_str = hole_no_temp - 9\n",
        "\n",
        "        row[f'stroke_{hole_prefix}_{hole_no_str}'] = hole['stroke']\n",
        "        row[f'putt_{hole_prefix}_{hole_no_str}'] = hole['putt']\n",
        "        row[f'penalty_{hole_prefix}_{hole_no_str}'] = hole['penalty']\n",
        "        row[f'fw_hit_{hole_prefix}_{hole_no_str}'] = 'Yes' if hole['fw_hit'] == 1 else 'No'\n",
        "\n",
        "    final_df_list.append(row)\n",
        "\n",
        "# 리스트를 데이터프레임으로 변환\n",
        "final_df = pd.DataFrame(final_df_list, columns=final_columns)\n",
        "\n",
        "# 데이터 저장 (CSV)\n",
        "final_df.to_csv(output_csv_file_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"  - 최종 데이터프레임을 '{output_csv_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터 저장 (Parquet)\n",
        "final_df.to_parquet(output_parquet_file_path, index=False)\n",
        "print(f\"  - 최종 데이터프레임을 '{output_parquet_file_path}'에 저장하였습니다. ({datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
        "\n",
        "# 데이터프레임의 데이터 일부 출력\n",
        "print(\"\\n  * Arranged Final Prediction DataFrame (final_df):\")\n",
        "display(final_df.head(18))\n",
        "\n",
        "# 데이터프레임의 정보 출력\n",
        "print(\"  * Arranged Final Prediction DataFrame Information (final_df):\")\n",
        "display_info_in_sections(final_df)\n",
        "\n",
        "# =================================================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ok9RNCza1mDq",
        "ojIv-O-OiY3G",
        "L1aZsFZPqOaR",
        "0y_yCIveE-Kd",
        "t3F82l62D43S",
        "qveNd_z4EQDZ",
        "gCbBVqgQimIl",
        "h3qPgYHdj1gk",
        "E4c7598skq4a",
        "bgjfle8Mux5L",
        "1EJ9ZctGvO1G",
        "V3yjw-eHxOsw",
        "9o_HXkTg0Y-0",
        "q6hzvbBFECr0",
        "bbuJbsUh2Dml",
        "PTBqcZbvyuoG"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}